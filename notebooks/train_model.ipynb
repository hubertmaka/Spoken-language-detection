{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1. Import libraries and dependencies",
   "id": "fe17e89353b6ef08"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T19:53:49.459253Z",
     "start_time": "2024-05-22T19:53:47.455443Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from src.preprocess.preprocess import Preprocess\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ],
   "id": "a6bf080f1b761de7",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-22 21:53:47.745085: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-22 21:53:47.747642: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-22 21:53:47.783660: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-22 21:53:48.436408: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hubert/Workspace/Python/ML Project/languages\n",
      "{'cs': '/home/hubert/Workspace/Python/ML Project/languages/cs', 'lt': '/home/hubert/Workspace/Python/ML Project/languages/lt', 'pl': '/home/hubert/Workspace/Python/ML Project/languages/pl'}\n",
      "{'cs': '/home/hubert/Workspace/Python/ML Project/languages/cs/validated.tsv', 'lt': '/home/hubert/Workspace/Python/ML Project/languages/lt/validated.tsv', 'pl': '/home/hubert/Workspace/Python/ML Project/languages/pl/validated.tsv'}\n",
      "{'cs': '/home/hubert/Workspace/Python/ML Project/languages/cs/clip_durations.tsv', 'lt': '/home/hubert/Workspace/Python/ML Project/languages/lt/clip_durations.tsv', 'pl': '/home/hubert/Workspace/Python/ML Project/languages/pl/clip_durations.tsv'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-22 21:53:49.245497: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:282] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. Preprocess audio",
   "id": "8c503ca62d34114e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T19:53:49.462968Z",
     "start_time": "2024-05-22T19:53:49.460571Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ORIGIN_SAMPLE_RATE = 48_000\n",
    "FINAL_SAMPLE_RATE = 16_000\n",
    "MAX_CLIENT_ID_AMOUNT = 3000\n",
    "MIN_CLIP_DURATION_MS = 2000\n",
    "SET_SIZE = 38_000\n",
    "BATCH_SIZE = 32"
   ],
   "id": "bcc6785fc37b96a1",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T19:53:49.516454Z",
     "start_time": "2024-05-22T19:53:49.464084Z"
    }
   },
   "cell_type": "code",
   "source": [
    "Preprocess.set_origin_sample_rate(ORIGIN_SAMPLE_RATE)\n",
    "Preprocess.set_final_sample_rate(FINAL_SAMPLE_RATE)\n",
    "Preprocess.set_max_client_id_amount(MAX_CLIENT_ID_AMOUNT)\n",
    "Preprocess.set_min_clip_duration_ms(MIN_CLIP_DURATION_MS)\n",
    "Preprocess.set_set_size(SET_SIZE)\n",
    "Preprocess.set_batch_size(BATCH_SIZE)"
   ],
   "id": "643cc795267762a6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'int'>\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T19:53:49.565479Z",
     "start_time": "2024-05-22T19:53:49.517674Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"Original sample rate: {Preprocess.ORIGIN_SAMPLE_RATE}\")\n",
    "print(f\"Final sample rate: {Preprocess.SAMPLE_RATE}\")\n",
    "print(f\"Max client id amount: {Preprocess.MAX_CLIENT_ID_AMOUNT}\")\n",
    "print(f\"Min clip duration in milliseconds: {Preprocess.MIN_CLIP_DURATION_MS}\")\n",
    "print(f\"Set size: {Preprocess.SET_SIZE}\")\n",
    "print(f\"One language set size: {Preprocess.ONE_LANG_SET_SIZE}\")\n",
    "\n",
    "print(\"-\"*25 + \"SETS SIZES\" + \"-\"*25)\n",
    "print(f\"Training set size: {Preprocess.SET_HPARAMS.train_size}\")\n",
    "print(f\"Val set size: {Preprocess.SET_HPARAMS.val_size}\")\n",
    "print(f\"Test set size: {Preprocess.SET_HPARAMS.test_size}\")\n",
    "print(f\"Is test + val + train is equal one lang set size: \"\n",
    "      f\"\\n{Preprocess.SET_HPARAMS.test_size + Preprocess.SET_HPARAMS.val_size + Preprocess.SET_HPARAMS.train_size} <= {Preprocess.ONE_LANG_SET_SIZE}\")"
   ],
   "id": "7722c767a96561c9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample rate: 48000\n",
      "Final sample rate: 16000\n",
      "Max client id amount: 3000\n",
      "Min clip duration in milliseconds: 2000\n",
      "Set size: 38000\n",
      "One language set size: 12666\n",
      "-------------------------SETS SIZES-------------------------\n",
      "Training set size: 7599\n",
      "Val set size: 2532\n",
      "Test set size: 2532\n",
      "Is test + val + train is equal one lang set size: \n",
      "12663 <= 12666\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T19:53:51.346631Z",
     "start_time": "2024-05-22T19:53:49.566363Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start = time.time()\n",
    "Preprocess.preprocess()\n",
    "end = time.time()\n",
    "print(f\"Preprocess time: {end - start}\")"
   ],
   "id": "76837a64d644a926",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROCESSED LANGUAGES: cs\n",
      "---AUDIO META INFO DONE cs---\n",
      "---SET SPLIT DONE 0 cs---\n",
      "train size: 3798\n",
      "len train: 3798\n",
      "Missing probes: 0\n",
      "1267\n",
      "1267\n",
      "3798\n",
      "--------------------------\n",
      "1267\n",
      "1267\n",
      "3798\n",
      "--------------------------\n",
      "--------------------------\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'path'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[0;32m----> 2\u001B[0m \u001B[43mPreprocess\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpreprocess\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      3\u001B[0m end \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPreprocess time: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mend\u001B[38;5;250m \u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;250m \u001B[39mstart\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/Workspace/Python/ML Project/Spoken-language-detection/src/preprocess/preprocess.py:195\u001B[0m, in \u001B[0;36mPreprocess.preprocess\u001B[0;34m()\u001B[0m\n\u001B[1;32m    185\u001B[0m tuned_set_size \u001B[38;5;241m=\u001B[39m SetHyperparameters(men_size) \u001B[38;5;28;01mif\u001B[39;00m num \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m SetHyperparameters(women_size)\n\u001B[1;32m    186\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m need_fill:\n\u001B[1;32m    187\u001B[0m     \u001B[38;5;66;03m# tuned_set_size = SetHyperparameters(Preprocess.ONE_LANG_GENDER_SET_SIZE)\u001B[39;00m\n\u001B[1;32m    189\u001B[0m     df_filenames \u001B[38;5;241m=\u001B[39m \u001B[43mSplitSet\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    190\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdf\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgender_df\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    191\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmax_client_id_amount\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mPreprocess\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mMAX_CLIENT_ID_AMOUNT\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    192\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmin_clip_duration_ms\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mPreprocess\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mMIN_CLIP_DURATION_MS\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    193\u001B[0m \u001B[43m        \u001B[49m\u001B[43mset_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mmen_size\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mnum\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m==\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mwomen_size\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    194\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlang\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlang\u001B[49m\n\u001B[0;32m--> 195\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_filenames\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    196\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    197\u001B[0m     \u001B[38;5;66;03m# tuned_set_size = SetHyperparameters(men_size) if num == 0 else SetHyperparameters(women_size)\u001B[39;00m\n\u001B[1;32m    198\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTUNING SET SIZE\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/Workspace/Python/ML Project/Spoken-language-detection/src/preprocess/split.py:54\u001B[0m, in \u001B[0;36mSplitSet.get_filenames\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     49\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_filenames\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mdict\u001B[39m[\u001B[38;5;28mstr\u001B[39m, pd\u001B[38;5;241m.\u001B[39mDataFrame]:\n\u001B[1;32m     50\u001B[0m     \u001B[38;5;66;03m# print(self._df_train)\u001B[39;00m\n\u001B[1;32m     51\u001B[0m     \u001B[38;5;66;03m# print(self._df_val)\u001B[39;00m\n\u001B[1;32m     52\u001B[0m     \u001B[38;5;66;03m# print(self._df_test)\u001B[39;00m\n\u001B[1;32m     53\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m {\n\u001B[0;32m---> 54\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_df_train\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mpath\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241m.\u001B[39mapply(\u001B[38;5;28;01mlambda\u001B[39;00m fn: os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpaths_info\u001B[38;5;241m.\u001B[39mLANG_DIRS\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlang), \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mclips\u001B[39m\u001B[38;5;124m'\u001B[39m, fn)),\n\u001B[1;32m     55\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mval\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_df_val[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpath\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mapply(\u001B[38;5;28;01mlambda\u001B[39;00m fn: os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpaths_info\u001B[38;5;241m.\u001B[39mLANG_DIRS\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlang),\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mclips\u001B[39m\u001B[38;5;124m'\u001B[39m, fn)),\n\u001B[1;32m     56\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtest\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_df_test[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpath\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mapply(\u001B[38;5;28;01mlambda\u001B[39;00m fn: os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpaths_info\u001B[38;5;241m.\u001B[39mLANG_DIRS\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlang),\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mclips\u001B[39m\u001B[38;5;124m'\u001B[39m, fn))\n\u001B[1;32m     57\u001B[0m     }\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/Spoken-language-detection-jJHkTLde/lib/python3.11/site-packages/pandas/core/frame.py:4102\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   4100\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mnlevels \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m   4101\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_multilevel(key)\n\u001B[0;32m-> 4102\u001B[0m indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   4103\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[1;32m   4104\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m [indexer]\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/Spoken-language-detection-jJHkTLde/lib/python3.11/site-packages/pandas/core/indexes/range.py:417\u001B[0m, in \u001B[0;36mRangeIndex.get_loc\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m    415\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[1;32m    416\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(key, Hashable):\n\u001B[0;32m--> 417\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key)\n\u001B[1;32m    418\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_indexing_error(key)\n\u001B[1;32m    419\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key)\n",
      "\u001B[0;31mKeyError\u001B[0m: 'path'"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def _set_train_val_test_sizes(_set_size) -> None:\n",
    "    _train_size = int(_set_size * 0.6) if _set_size % 2 == 0 else int(_set_size * 0.6) - 1\n",
    "    _val_size = int((_set_size - _train_size) // 2) if _train_size % 2 == 0 else int((_set_size - _train_size) // 2) - 1\n",
    "    _test_size = _val_size\n",
    "    print(_train_size)\n",
    "    print(_val_size)\n",
    "    print(_test_size)\n",
    "    \n",
    "_set_train_val_test_sizes(650 // 3)"
   ],
   "id": "80dbbc8864fc7e80",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# for audio, label in Preprocess.train_dataset.take(120):\n",
    "#     print(audio.shape)"
   ],
   "id": "a8182e67c8647adf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# for audio, label in Preprocess.val_dataset.take(112):\n",
    "#     print(audio.shape)"
   ],
   "id": "bff7b8fade044dcd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# for audio, label in Preprocess.test_dataset.take(112):\n",
    "#     print(audio.shape)"
   ],
   "id": "2b8d692ce5c372e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "counter = 0\n",
    "start = time.time()\n",
    "for batch, label in Preprocess.train_dataset:\n",
    "    print(batch.shape)\n",
    "    for sample in batch:\n",
    "        print(sample)\n",
    "        counter += 1\n",
    "end = time.time()\n",
    "print(f\"Train it time: {end - start}\")\n",
    "print(counter)\n"
   ],
   "id": "9ce89707caf7183f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "counter = 0\n",
    "start = time.time()\n",
    "for batch, label in Preprocess.val_dataset:\n",
    "    print(batch.shape)\n",
    "    for sample in batch:\n",
    "        print(sample)\n",
    "        counter += 1\n",
    "end = time.time()\n",
    "print(f\"Val it time: {end - start}\")\n",
    "print(counter)"
   ],
   "id": "c57622f982018832",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "counter = 0\n",
    "start = time.time()\n",
    "for batch, label in Preprocess.test_dataset:\n",
    "    print(batch.shape)\n",
    "    for sample in batch:\n",
    "        print(sample)\n",
    "        counter += 1\n",
    "end = time.time()\n",
    "print(f\"Test it time: {end - start}\")\n",
    "print(counter)"
   ],
   "id": "722354f91273be74",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "Preprocess.train_dataset.as_numpy_iterator().next()",
   "id": "311505f93fdb0834",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "samples, labels = Preprocess.train_dataset.as_numpy_iterator().next()\n",
    "print()\n",
    "print(samples.shape, labels.shape)\n",
    "samples, labels = Preprocess.val_dataset.as_numpy_iterator().next()\n",
    "print(samples.shape, labels.shape)\n",
    "samples, labels = Preprocess.test_dataset.as_numpy_iterator().next()\n",
    "print(samples.shape, labels.shape)"
   ],
   "id": "d2ba8468c9faf68",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "samples, labels = Preprocess.train_dataset.as_numpy_iterator().next()",
   "id": "2e02ad17a22a72e4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "samples.shape",
   "id": "9dd8ca874fcaef1f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "95df6c4a43c91a86",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "input_shape = samples.shape[1:]\n",
    "input_shape"
   ],
   "id": "2d0a75ded54f802a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "Preprocess.test_dataset.element_spec",
   "id": "ba954c12ce6cdd72",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "Preprocess.val_dataset.element_spec",
   "id": "b8b5ff5286950b7b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "Preprocess.train_dataset.element_spec",
   "id": "398c95333527cc46",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4. Create model",
   "id": "ee913c5ee6ad12d6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "5dfd1206f7373abf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# model = keras.Sequential([\n",
    "#     layers.Input(shape=input_shape),\n",
    "#     layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "#     layers.MaxPooling2D((2, 2)),\n",
    "#     layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "#     layers.MaxPooling2D((2, 2)),\n",
    "#     layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "#     layers.Flatten(),\n",
    "#     layers.Dense(64, activation='relu'),\n",
    "#     layers.Dense(3, activation='softmax')\n",
    "# ])\n",
    "# model.summary()"
   ],
   "id": "6a03617d372142d3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])",
   "id": "505a64a885744d73",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "25912e7fbc73fe70",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "Preprocess.train_dataset.element_spec",
   "id": "9c188e2dbffef498",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "Preprocess.val_dataset.element_spec",
   "id": "10cb85ef31e81171",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# history = model.fit(Preprocess.train_dataset, epochs=10, validation_data=Preprocess.val_dataset, batch_size=BATCH_SIZE)",
   "id": "69a8906aa7b7b2ae",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# test_loss, test_acc = model.evaluate(Preprocess.test_dataset, verbose=2)\n",
    "# print(f'\\nTest accuracy: {test_acc}')"
   ],
   "id": "5cad03e9342f7d90",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# plt.plot(history.history['accuracy'], label='accuracy')\n",
    "# plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.ylim([0.5, 1])\n",
    "# plt.legend(loc='lower right')\n",
    "# plt.show()\n"
   ],
   "id": "4ded628e8da52681",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "f205d84d466168fa",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
