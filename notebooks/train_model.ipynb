{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1. Import libraries and dependencies",
   "id": "fe17e89353b6ef08"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T09:48:18.431039Z",
     "start_time": "2024-05-23T09:48:16.544123Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from src.preprocess.preprocess import Preprocess\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ],
   "id": "a6bf080f1b761de7",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-23 11:48:16.807835: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-23 11:48:16.810539: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-23 11:48:16.845975: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-23 11:48:17.497095: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hubert/Workspace/Python/ML Project/languages\n",
      "{'cs': '/home/hubert/Workspace/Python/ML Project/languages/cs', 'lt': '/home/hubert/Workspace/Python/ML Project/languages/lt', 'pl': '/home/hubert/Workspace/Python/ML Project/languages/pl'}\n",
      "{'cs': '/home/hubert/Workspace/Python/ML Project/languages/cs/validated.tsv', 'lt': '/home/hubert/Workspace/Python/ML Project/languages/lt/validated.tsv', 'pl': '/home/hubert/Workspace/Python/ML Project/languages/pl/validated.tsv'}\n",
      "{'cs': '/home/hubert/Workspace/Python/ML Project/languages/cs/clip_durations.tsv', 'lt': '/home/hubert/Workspace/Python/ML Project/languages/lt/clip_durations.tsv', 'pl': '/home/hubert/Workspace/Python/ML Project/languages/pl/clip_durations.tsv'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-23 11:48:18.142302: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:282] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. Preprocess audio",
   "id": "8c503ca62d34114e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T09:48:18.435273Z",
     "start_time": "2024-05-23T09:48:18.432459Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ORIGIN_SAMPLE_RATE = 48_000\n",
    "FINAL_SAMPLE_RATE = 16_000\n",
    "MAX_CLIENT_ID_AMOUNT = 3000\n",
    "MIN_CLIP_DURATION_MS = 2000\n",
    "SET_SIZE = 12_000\n",
    "BATCH_SIZE = 32"
   ],
   "id": "bcc6785fc37b96a1",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T09:48:18.490121Z",
     "start_time": "2024-05-23T09:48:18.436081Z"
    }
   },
   "cell_type": "code",
   "source": [
    "Preprocess.set_origin_sample_rate(ORIGIN_SAMPLE_RATE)\n",
    "Preprocess.set_final_sample_rate(FINAL_SAMPLE_RATE)\n",
    "Preprocess.set_max_client_id_amount(MAX_CLIENT_ID_AMOUNT)\n",
    "Preprocess.set_min_clip_duration_ms(MIN_CLIP_DURATION_MS)\n",
    "Preprocess.set_set_size(SET_SIZE)\n",
    "Preprocess.set_batch_size(BATCH_SIZE)"
   ],
   "id": "643cc795267762a6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'int'>\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T09:48:18.538285Z",
     "start_time": "2024-05-23T09:48:18.491044Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"Original sample rate: {Preprocess.ORIGIN_SAMPLE_RATE}\")\n",
    "print(f\"Final sample rate: {Preprocess.SAMPLE_RATE}\")\n",
    "print(f\"Max client id amount: {Preprocess.MAX_CLIENT_ID_AMOUNT}\")\n",
    "print(f\"Min clip duration in milliseconds: {Preprocess.MIN_CLIP_DURATION_MS}\")\n",
    "print(f\"Set size: {Preprocess.SET_SIZE}\")\n",
    "print(f\"One language set size: {Preprocess.ONE_LANG_SET_SIZE}\")\n",
    "\n",
    "print(\"-\"*25 + \"SETS SIZES\" + \"-\"*25)\n",
    "print(f\"Training set size: {Preprocess.SET_HPARAMS.train_size}\")\n",
    "print(f\"Val set size: {Preprocess.SET_HPARAMS.val_size}\")\n",
    "print(f\"Test set size: {Preprocess.SET_HPARAMS.test_size}\")\n",
    "print(f\"Is test + val + train is equal one lang set size: \"\n",
    "      f\"\\n{Preprocess.SET_HPARAMS.test_size + Preprocess.SET_HPARAMS.val_size + Preprocess.SET_HPARAMS.train_size} <= {Preprocess.ONE_LANG_SET_SIZE}\")"
   ],
   "id": "7722c767a96561c9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample rate: 48000\n",
      "Final sample rate: 16000\n",
      "Max client id amount: 3000\n",
      "Min clip duration in milliseconds: 2000\n",
      "Set size: 12000\n",
      "One language set size: 4000\n",
      "-------------------------SETS SIZES-------------------------\n",
      "Training set size: 2400\n",
      "Val set size: 800\n",
      "Test set size: 800\n",
      "Is test + val + train is equal one lang set size: \n",
      "4000 <= 4000\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T09:48:23.462959Z",
     "start_time": "2024-05-23T09:48:18.539680Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start = time.time()\n",
    "Preprocess.split_filenames()\n",
    "end = time.time()\n",
    "print(f\"Preprocess time: {end - start}\")\n",
    "print(len(Preprocess.TRAIN_FILENAMES))\n",
    "print(len(Preprocess.VAL_FILENAMES))\n",
    "print(len(Preprocess.TEST_FILENAMES))"
   ],
   "id": "76837a64d644a926",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROCESSED LANGUAGES: cs\n",
      "---AUDIO META INFO DONE cs---\n",
      "1200\n",
      "400\n",
      "400\n",
      "---SET SPLIT DONE 0 cs---\n",
      "Missing probes: 0\n",
      "Tuned train size: 1200\n",
      "Tuned val size: 400\n",
      "Tuned test size: 400\n",
      "--------------------------\n",
      "Test size:  400\n",
      "Val size:  400\n",
      "Train size:  1200\n",
      "--------------------------\n",
      "--------------------------\n",
      "1200\n",
      "400\n",
      "400\n",
      "---SET SPLIT DONE 1 cs---\n",
      "Missing probes: 0\n",
      "Tuned train size: 1200\n",
      "Tuned val size: 400\n",
      "Tuned test size: 400\n",
      "--------------------------\n",
      "Test size:  400\n",
      "Val size:  400\n",
      "Train size:  1200\n",
      "--------------------------\n",
      "--------------------------\n",
      "PROCESSED LANGUAGES: lt\n",
      "---AUDIO META INFO DONE lt---\n",
      "1200\n",
      "400\n",
      "400\n",
      "---SET SPLIT DONE 0 lt---\n",
      "Missing probes: 0\n",
      "Tuned train size: 1200\n",
      "Tuned val size: 400\n",
      "Tuned test size: 400\n",
      "--------------------------\n",
      "Test size:  400\n",
      "Val size:  400\n",
      "Train size:  1200\n",
      "--------------------------\n",
      "--------------------------\n",
      "1200\n",
      "400\n",
      "400\n",
      "---SET SPLIT DONE 1 lt---\n",
      "Missing probes: 0\n",
      "Tuned train size: 1200\n",
      "Tuned val size: 400\n",
      "Tuned test size: 400\n",
      "--------------------------\n",
      "Test size:  400\n",
      "Val size:  400\n",
      "Train size:  1200\n",
      "--------------------------\n",
      "--------------------------\n",
      "PROCESSED LANGUAGES: pl\n",
      "---AUDIO META INFO DONE pl---\n",
      "1200\n",
      "400\n",
      "400\n",
      "---SET SPLIT DONE 0 pl---\n",
      "Missing probes: 0\n",
      "Tuned train size: 1200\n",
      "Tuned val size: 400\n",
      "Tuned test size: 400\n",
      "--------------------------\n",
      "Test size:  400\n",
      "Val size:  400\n",
      "Train size:  1200\n",
      "--------------------------\n",
      "--------------------------\n",
      "1200\n",
      "400\n",
      "400\n",
      "---SET SPLIT DONE 1 pl---\n",
      "Missing probes: 0\n",
      "Tuned train size: 1200\n",
      "Tuned val size: 400\n",
      "Tuned test size: 400\n",
      "--------------------------\n",
      "Test size:  400\n",
      "Val size:  400\n",
      "Train size:  1200\n",
      "--------------------------\n",
      "--------------------------\n",
      "Preprocess time: 4.875028610229492\n",
      "7200\n",
      "2400\n",
      "2400\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T09:48:23.466567Z",
     "start_time": "2024-05-23T09:48:23.463658Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def _set_train_val_test_sizes(_set_size) -> None:\n",
    "    _train_size = int(_set_size * 0.6) if _set_size % 2 == 0 else int(_set_size * 0.6) - 1\n",
    "    _val_size = int((_set_size - _train_size) // 2) if _train_size % 2 == 0 else int((_set_size - _train_size) // 2) - 1\n",
    "    _test_size = _val_size\n",
    "    print(_train_size)\n",
    "    print(_val_size)\n",
    "    print(_test_size)\n",
    "    \n",
    "_set_train_val_test_sizes(650 // 3)"
   ],
   "id": "80dbbc8864fc7e80",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129\n",
      "42\n",
      "42\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T09:48:24.035382Z",
     "start_time": "2024-05-23T09:48:23.467341Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# for audio, label in Preprocess.train_dataset.take(120):\n",
    "#     print(audio.shape)"
   ],
   "id": "a8182e67c8647adf",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T09:48:24.083002Z",
     "start_time": "2024-05-23T09:48:24.036202Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# for audio, label in Preprocess.val_dataset.take(112):\n",
    "#     print(audio.shape)"
   ],
   "id": "bff7b8fade044dcd",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T09:48:24.131721Z",
     "start_time": "2024-05-23T09:48:24.083762Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# for audio, label in Preprocess.test_dataset.take(112):\n",
    "#     print(audio.shape)"
   ],
   "id": "2b8d692ce5c372e",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T09:48:24.184405Z",
     "start_time": "2024-05-23T09:48:24.132572Z"
    }
   },
   "cell_type": "code",
   "source": [
    "counter = 0\n",
    "start = time.time()\n",
    "for batch, label in Preprocess.train_dataset:\n",
    "    print(batch.shape)\n",
    "    for sample in batch:\n",
    "        print(sample)\n",
    "        counter += 1\n",
    "end = time.time()\n",
    "print(f\"Train it time: {end - start}\")\n",
    "print(counter)\n"
   ],
   "id": "9ce89707caf7183f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train it time: 0.004559516906738281\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-23 11:48:24.182545: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T09:48:24.230980Z",
     "start_time": "2024-05-23T09:48:24.185298Z"
    }
   },
   "cell_type": "code",
   "source": [
    "counter = 0\n",
    "start = time.time()\n",
    "for batch, label in Preprocess.val_dataset:\n",
    "    print(batch.shape)\n",
    "    for sample in batch:\n",
    "        print(sample)\n",
    "        counter += 1\n",
    "end = time.time()\n",
    "print(f\"Val it time: {end - start}\")\n",
    "print(counter)"
   ],
   "id": "c57622f982018832",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val it time: 0.002330780029296875\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-23 11:48:24.229142: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T09:48:24.279577Z",
     "start_time": "2024-05-23T09:48:24.231837Z"
    }
   },
   "cell_type": "code",
   "source": [
    "counter = 0\n",
    "start = time.time()\n",
    "for batch, label in Preprocess.test_dataset:\n",
    "    print(batch.shape)\n",
    "    for sample in batch:\n",
    "        print(sample)\n",
    "        counter += 1\n",
    "end = time.time()\n",
    "print(f\"Test it time: {end - start}\")\n",
    "print(counter)"
   ],
   "id": "722354f91273be74",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test it time: 0.0024290084838867188\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-23 11:48:24.277822: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T09:48:25.169146Z",
     "start_time": "2024-05-23T09:48:24.280402Z"
    }
   },
   "cell_type": "code",
   "source": "Preprocess.train_dataset.as_numpy_iterator().next()",
   "id": "311505f93fdb0834",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-23 11:48:24.324352: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mOutOfRangeError\u001B[0m                           Traceback (most recent call last)",
      "File \u001B[0;32m~/.local/share/virtualenvs/Spoken-language-detection-jJHkTLde/lib/python3.11/site-packages/tensorflow/python/data/ops/iterator_ops.py:809\u001B[0m, in \u001B[0;36mOwnedIterator.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    808\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 809\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_internal\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    810\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m errors\u001B[38;5;241m.\u001B[39mOutOfRangeError:\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/Spoken-language-detection-jJHkTLde/lib/python3.11/site-packages/tensorflow/python/data/ops/iterator_ops.py:772\u001B[0m, in \u001B[0;36mOwnedIterator._next_internal\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    771\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m context\u001B[38;5;241m.\u001B[39mexecution_mode(context\u001B[38;5;241m.\u001B[39mSYNC):\n\u001B[0;32m--> 772\u001B[0m   ret \u001B[38;5;241m=\u001B[39m \u001B[43mgen_dataset_ops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43miterator_get_next\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    773\u001B[0m \u001B[43m      \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_iterator_resource\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    774\u001B[0m \u001B[43m      \u001B[49m\u001B[43moutput_types\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_flat_output_types\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    775\u001B[0m \u001B[43m      \u001B[49m\u001B[43moutput_shapes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_flat_output_shapes\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    777\u001B[0m   \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    778\u001B[0m     \u001B[38;5;66;03m# Fast path for the case `self._structure` is not a nested structure.\u001B[39;00m\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/Spoken-language-detection-jJHkTLde/lib/python3.11/site-packages/tensorflow/python/ops/gen_dataset_ops.py:3086\u001B[0m, in \u001B[0;36miterator_get_next\u001B[0;34m(iterator, output_types, output_shapes, name)\u001B[0m\n\u001B[1;32m   3085\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m _core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m-> 3086\u001B[0m   \u001B[43m_ops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mraise_from_not_ok_status\u001B[49m\u001B[43m(\u001B[49m\u001B[43me\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3087\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m _core\u001B[38;5;241m.\u001B[39m_FallbackException:\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/Spoken-language-detection-jJHkTLde/lib/python3.11/site-packages/tensorflow/python/framework/ops.py:5983\u001B[0m, in \u001B[0;36mraise_from_not_ok_status\u001B[0;34m(e, name)\u001B[0m\n\u001B[1;32m   5982\u001B[0m e\u001B[38;5;241m.\u001B[39mmessage \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m name: \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mstr\u001B[39m(name \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n\u001B[0;32m-> 5983\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_status_to_exception(e) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[0;31mOutOfRangeError\u001B[0m: {{function_node __wrapped__IteratorGetNext_output_types_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} End of sequence [Op:IteratorGetNext] name: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mStopIteration\u001B[0m                             Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[13], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mPreprocess\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_dataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mas_numpy_iterator\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnext\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/Spoken-language-detection-jJHkTLde/lib/python3.11/site-packages/tensorflow/python/data/ops/dataset_ops.py:4729\u001B[0m, in \u001B[0;36mNumpyIterator.next\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   4728\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mnext\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m-> 4729\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__next__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/Spoken-language-detection-jJHkTLde/lib/python3.11/site-packages/tensorflow/python/data/ops/dataset_ops.py:4726\u001B[0m, in \u001B[0;36mNumpyIterator.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   4723\u001B[0m     numpy\u001B[38;5;241m.\u001B[39msetflags(write\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m   4724\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m numpy\n\u001B[0;32m-> 4726\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m nest\u001B[38;5;241m.\u001B[39mmap_structure(to_numpy, \u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_iterator\u001B[49m\u001B[43m)\u001B[49m)\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/Spoken-language-detection-jJHkTLde/lib/python3.11/site-packages/tensorflow/python/data/ops/iterator_ops.py:811\u001B[0m, in \u001B[0;36mOwnedIterator.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    809\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_internal()\n\u001B[1;32m    810\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m errors\u001B[38;5;241m.\u001B[39mOutOfRangeError:\n\u001B[0;32m--> 811\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m\n",
      "\u001B[0;31mStopIteration\u001B[0m: "
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "samples, labels = Preprocess.train_dataset.as_numpy_iterator().next()\n",
    "print()\n",
    "print(samples.shape, labels.shape)\n",
    "samples, labels = Preprocess.val_dataset.as_numpy_iterator().next()\n",
    "print(samples.shape, labels.shape)\n",
    "samples, labels = Preprocess.test_dataset.as_numpy_iterator().next()\n",
    "print(samples.shape, labels.shape)"
   ],
   "id": "d2ba8468c9faf68",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "samples, labels = Preprocess.train_dataset.as_numpy_iterator().next()",
   "id": "2e02ad17a22a72e4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "samples.shape",
   "id": "9dd8ca874fcaef1f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "95df6c4a43c91a86",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "input_shape = samples.shape[1:]\n",
    "input_shape"
   ],
   "id": "2d0a75ded54f802a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "Preprocess.test_dataset.element_spec",
   "id": "ba954c12ce6cdd72",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "Preprocess.val_dataset.element_spec",
   "id": "b8b5ff5286950b7b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "Preprocess.train_dataset.element_spec",
   "id": "398c95333527cc46",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4. Create model",
   "id": "ee913c5ee6ad12d6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "5dfd1206f7373abf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# model = keras.Sequential([\n",
    "#     layers.Input(shape=input_shape),\n",
    "#     layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "#     layers.MaxPooling2D((2, 2)),\n",
    "#     layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "#     layers.MaxPooling2D((2, 2)),\n",
    "#     layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "#     layers.Flatten(),\n",
    "#     layers.Dense(64, activation='relu'),\n",
    "#     layers.Dense(3, activation='softmax')\n",
    "# ])\n",
    "# model.summary()"
   ],
   "id": "6a03617d372142d3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])",
   "id": "505a64a885744d73",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "25912e7fbc73fe70",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "Preprocess.train_dataset.element_spec",
   "id": "9c188e2dbffef498",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "Preprocess.val_dataset.element_spec",
   "id": "10cb85ef31e81171",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# history = model.fit(Preprocess.train_dataset, epochs=10, validation_data=Preprocess.val_dataset, batch_size=BATCH_SIZE)",
   "id": "69a8906aa7b7b2ae",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# test_loss, test_acc = model.evaluate(Preprocess.test_dataset, verbose=2)\n",
    "# print(f'\\nTest accuracy: {test_acc}')"
   ],
   "id": "5cad03e9342f7d90",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# plt.plot(history.history['accuracy'], label='accuracy')\n",
    "# plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.ylim([0.5, 1])\n",
    "# plt.legend(loc='lower right')\n",
    "# plt.show()\n"
   ],
   "id": "4ded628e8da52681",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "f205d84d466168fa",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
