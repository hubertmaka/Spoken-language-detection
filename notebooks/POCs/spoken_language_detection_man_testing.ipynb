{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Spoken language detection"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d758a0066910796d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7b90391470eb7da4"
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import IPython"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:53:51.739918300Z",
     "start_time": "2024-05-06T07:53:50.475044600Z"
    }
   },
   "id": "e771baad4b9578e9",
   "execution_count": 72,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "PL_DIR = os.path.join('languages_audio', 'languages_audio_wav', 'pl', 'clips')\n",
    "PL_DIR"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4343ebee9c38ae63",
   "execution_count": 85,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# create tensorflow dataset\n",
    "pl_dataset = tf.data.Dataset.list_files(PL_DIR + '\\*.wav')\n",
    "pl_dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ba1dbf66c6eda4bf",
   "execution_count": 86,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "pl_dataset.as_numpy_iterator().next()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9a641093a2c580c2",
   "execution_count": 87,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "pl_dataset.as_numpy_iterator().next()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "88e49cfbfba3bafb",
   "execution_count": 88,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df = pd.read_csv(os.path.join('languages_audio', 'languages_audio_mp3', 'pl', 'validated.tsv'), sep='\\t')\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b25c7c351f5d432",
   "execution_count": 89,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df[df['gender'] == 'female_feminine']"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a419164919440f40",
   "execution_count": 90,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df[df['gender'] == 'male_masculine']"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6c0ecc7926645f66",
   "execution_count": 91,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df.groupby('sentence_id').count()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "805a0e99ad4a6f32",
   "execution_count": 92,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df['sentence_id'].value_counts()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3765e7a31c9a897d",
   "execution_count": 93,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df['sentence_id'].nunique()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "91c679c99c892a10",
   "execution_count": 94,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df['client_id'].value_counts().sort_values(ascending=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fedb03302fc130ee",
   "execution_count": 95,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:53:56.540044500Z",
     "start_time": "2024-05-06T07:53:56.139766600Z"
    }
   },
   "id": "a8d7ac801357330b",
   "execution_count": 95,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df[['sentence_id', 'client_id']].groupby(by='sentence_id').count().sort_values(by='client_id', ascending=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:53:56.602576700Z",
     "start_time": "2024-05-06T07:53:56.155234Z"
    }
   },
   "id": "b66628d65d38615e",
   "execution_count": 96,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df[['client_id', 'sentence_id']].sort_values(by='client_id', ascending=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:53:56.612550700Z",
     "start_time": "2024-05-06T07:53:56.232714800Z"
    }
   },
   "id": "788ead3deb0c642a",
   "execution_count": 97,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df[['client_id', 'sentence_id']].sort_values(by='client_id', ascending=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:53:56.637104100Z",
     "start_time": "2024-05-06T07:53:56.296418400Z"
    }
   },
   "id": "54720b0b0d5e35f9",
   "execution_count": 98,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df[df['client_id'] == 'ffffc00a5ed69f08a486837064ec2caeff21fe06264c3dd733f633fb6c2ae9aeb561a5a6f43e000554d4b3cc171644ba4ce971177af1cb54f9bd8cc153e71a5c']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:53:56.680393Z",
     "start_time": "2024-05-06T07:53:56.356283300Z"
    }
   },
   "id": "28a7c157bc223a7",
   "execution_count": 99,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# # sprawdzenie czy client_id oraz sequence_id się nie duplikują (czy jeden klient ma rózne sekwencej)\n",
    "# \n",
    "# for client_id in df['client_id'].unique():\n",
    "#     sentence_count = df['sentence_id'][df['client_id']  == client_id].count()\n",
    "#     client_id_count = df['client_id'][df['client_id']  == client_id].value_counts().iloc[0]\n",
    "#     if sentence_count != client_id_count:\n",
    "#         print(True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:53:56.684382200Z",
     "start_time": "2024-05-06T07:53:56.389889900Z"
    }
   },
   "id": "59ec3f2d2259223d",
   "execution_count": 100,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df['sentence_id'][df['client_id']  == 'ffffc00a5ed69f08a486837064ec2caeff21fe06264c3dd733f633fb6c2ae9aeb561a5a6f43e000554d4b3cc171644ba4ce971177af1cb54f9bd8cc153e71a5c'].count()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:53:56.758783300Z",
     "start_time": "2024-05-06T07:53:56.405846400Z"
    }
   },
   "id": "589f00618f423817",
   "execution_count": 101,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df['client_id'][df['client_id']  == 'ffffc00a5ed69f08a486837064ec2caeff21fe06264c3dd733f633fb6c2ae9aeb561a5a6f43e000554d4b3cc171644ba4ce971177af1cb54f9bd8cc153e71a5c'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:53:56.804840300Z",
     "start_time": "2024-05-06T07:53:56.419810Z"
    }
   },
   "id": "833e078c9b16e7e2",
   "execution_count": 102,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# TODO: WZiąć plik validated.tsv nastepnie podzielić go na mężczyzn i kobiety (dwa osobne dataset). następnie wrzucać do każdego ze zbiorów (najpiew testwoy, walidacyjny, treningowy) client_id od najmniejszej liczby wystąpień w obydwu  dopasować czas trwania każdej próbki (najpierw obcinać od środka, potem dopełniać zerami), zmienić na spektogram i dopiero wtedy dodać (koniec funkcji). druga funkcja będzie jako augumentowanie losowych danych (losowo wybiera funkcję która coś zrobi z danymi) jeżeli moje zbiory kobiet i mężczyzn nie będą spełniały wymaganej ilości próbek którą się poda. Na wyjściu ma być tensor z próbkami spektogramu. To zrobić finalnie dla każdego folderu (języka). Wtedy dopiero dodać label w formie one hot encoding"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:53:56.825447600Z",
     "start_time": "2024-05-06T07:53:56.434790Z"
    }
   },
   "id": "b41eb727ab7bcbf8",
   "execution_count": 103,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load data:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d07b8080fb6705c7"
  },
  {
   "cell_type": "code",
   "source": [
    "df = pd.read_csv(os.path.join('languages_audio', 'languages_audio_mp3', 'pl', 'validated.tsv'), sep='\\t', usecols=['client_id', 'path', 'sentence_id', 'gender', 'locale'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:53:57.867116100Z",
     "start_time": "2024-05-06T07:53:56.451252900Z"
    }
   },
   "id": "1ba578e1c67f2d8d",
   "execution_count": 104,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Change mp3 to wav name"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8f69ec6d7189b945"
  },
  {
   "cell_type": "code",
   "source": [
    "df = df.apply(lambda path: path.str.replace('.mp3', '.wav'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:53:58.046649600Z",
     "start_time": "2024-05-06T07:53:56.858866900Z"
    }
   },
   "id": "9422e72ec897347b",
   "execution_count": 105,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Split to woman and man sets"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e3481591ddd6b352"
  },
  {
   "cell_type": "code",
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:53:58.051636700Z",
     "start_time": "2024-05-06T07:53:56.983040900Z"
    }
   },
   "id": "437897c4a0dd254f",
   "execution_count": 106,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "woman_filter = df['gender'] == 'female_feminine'\n",
    "man_filter = df['gender'] == 'male_masculine'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:53:58.179050800Z",
     "start_time": "2024-05-06T07:53:56.999996100Z"
    }
   },
   "id": "5ea864f56b635651",
   "execution_count": 107,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df_women = df[woman_filter]\n",
    "df_women"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:53:58.197614Z",
     "start_time": "2024-05-06T07:53:57.013958300Z"
    }
   },
   "id": "283bff5acfcbbefb",
   "execution_count": 108,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df_men = df[man_filter]\n",
    "df_men"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:53:58.202590500Z",
     "start_time": "2024-05-06T07:53:57.030912600Z"
    }
   },
   "id": "d227f88872caa27c",
   "execution_count": 109,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Set number of probes in my set and split it to train, validate and test"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bf90c16bcfef86e1"
  },
  {
   "cell_type": "code",
   "source": [
    "SET_SIZE = 1_000\n",
    "MAX_NUMBER_OF_CLIENT_ID = 3000\n",
    "MIN_CLIP_DURATION = 4000 #  clip time in [ms]\n",
    "\n",
    "TRAIN_SIZE = int(SET_SIZE * 0.6)\n",
    "VAL_SIZE = int((SET_SIZE - TRAIN_SIZE) // 2)\n",
    "TEST_SIZE = SET_SIZE - TRAIN_SIZE - VAL_SIZE\n",
    "\n",
    "print(f'Train size: {TRAIN_SIZE}')\n",
    "print(f'Validation size: {VAL_SIZE}')\n",
    "print(f'Test size: {TEST_SIZE}')\n",
    "print(f'Sum of sizes: {TRAIN_SIZE + VAL_SIZE + TEST_SIZE} is equal to SET_SIZE {TRAIN_SIZE + VAL_SIZE + TEST_SIZE == SET_SIZE}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:53:58.218746700Z",
     "start_time": "2024-05-06T07:53:57.061830400Z"
    }
   },
   "id": "73b6742e55cd46ce",
   "execution_count": 110,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Select probes with min that time \n",
    "df_clips_duration = pd.read_csv(os.path.join('languages_audio', 'languages_audio_mp3', 'pl', 'clip_durations.tsv'), sep='\\t')\n",
    "df_clips_duration['clip'] = df_clips_duration['clip'].apply(lambda clip: clip.replace('.mp3', '.wav'))\n",
    "df_men = df_men.merge(df_clips_duration, left_on='path', right_on='clip')\n",
    "df_men"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:53:58.227700200Z",
     "start_time": "2024-05-06T07:53:57.078785Z"
    }
   },
   "id": "2bc35c9fa1f2a04a",
   "execution_count": 111,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "# \n",
    "# for i in range(len(df_clips_duration)):\n",
    "#     print(i)\n",
    "#     row_in_df = df_men[df_men['path']== df_clips_duration.iloc[i]['clip']] \n",
    "#     if (df_clips_duration.iloc[i]['duration[ms]'] >= MIN_CLIP_DURATION) and (len(row_in_df) >= 0):\n",
    "#         rows_over_min_dur_time = pd.concat([rows_over_min_dur_time, row_in_df])\n",
    "#     else:\n",
    "#         rows_under_min_dur_time = pd.concat([rows_under_min_dur_time, row_in_df])\n",
    "# \n",
    "# \n",
    "\n",
    "rows_over_min_dur_time = df_men[df_men['duration[ms]'] >= MIN_CLIP_DURATION]\n",
    "rows_under_min_dur_time = df_men[df_men['duration[ms]'] < MIN_CLIP_DURATION]\n",
    "rows_over_min_dur_time"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:53:58.232685900Z",
     "start_time": "2024-05-06T07:53:57.279046300Z"
    }
   },
   "id": "a901ecef326bfb2e",
   "execution_count": 112,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "rows_under_min_dur_time"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:53:58.237672600Z",
     "start_time": "2024-05-06T07:53:57.322951300Z"
    }
   },
   "id": "2fe7b8e7b0273d45",
   "execution_count": 113,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "if len(rows_over_min_dur_time) >= SET_SIZE:\n",
    "    df_men = rows_over_min_dur_time\n",
    "else:\n",
    "    df_men = pd.concat([rows_over_min_dur_time, rows_under_min_dur_time], ignore_index=True)[:SET_SIZE]\n",
    "\n",
    "df_men"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:53:58.260611Z",
     "start_time": "2024-05-06T07:53:57.353901600Z"
    }
   },
   "id": "3a4ae1c66f24659e",
   "execution_count": 114,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df_train = pd.DataFrame()\n",
    "df_val = pd.DataFrame()\n",
    "df_test = pd.DataFrame()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:53:58.264600200Z",
     "start_time": "2024-05-06T07:53:57.375523400Z"
    }
   },
   "id": "94f0a7c187961064",
   "execution_count": 115,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df_counted_id = df_men['client_id'].value_counts(ascending=True)\n",
    "df_counted_id"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:53:58.268590100Z",
     "start_time": "2024-05-06T07:53:57.401630Z"
    }
   },
   "id": "6219cdc9196dd3c8",
   "execution_count": 116,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "clients_form_origin_df = df_men[df_men['client_id'] == df_counted_id.index[200]]\n",
    "clients_form_origin_df1 = df_men[df_men['client_id'] == df_counted_id.index[201]]\n",
    "clients_form_origin_df1['client_id'].iloc[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:53:58.272579Z",
     "start_time": "2024-05-06T07:53:57.422190900Z"
    }
   },
   "id": "b9d38e4396a58bfc",
   "execution_count": 117,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "for i in range(len(df_counted_id)):\n",
    "    print(df_counted_id.index[i], df_counted_id.iloc[i])\n",
    "    rows_form_origin_df = df_men[df_men['client_id'] == df_counted_id.index[i]][:MAX_NUMBER_OF_CLIENT_ID]\n",
    "    if len(rows_form_origin_df) <= (TEST_SIZE - len(df_test)) and rows_form_origin_df['client_id'].iloc[0] not in df_test:\n",
    "        df_test = pd.concat([df_test, rows_form_origin_df], ignore_index=True)\n",
    "        continue\n",
    "    if len(rows_form_origin_df) <= (VAL_SIZE - len(df_val)):\n",
    "        df_val = pd.concat([df_val, rows_form_origin_df], ignore_index=True)\n",
    "        continue\n",
    "    if len(rows_form_origin_df) <= (TRAIN_SIZE - len(df_train)):\n",
    "        df_train = pd.concat([df_train, rows_form_origin_df], ignore_index=True)\n",
    "        continue\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:53:59.423049600Z",
     "start_time": "2024-05-06T07:53:57.455177500Z"
    }
   },
   "id": "537212501acba841",
   "execution_count": 119,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df_test"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:53:59.428035800Z",
     "start_time": "2024-05-06T07:53:59.033711600Z"
    }
   },
   "id": "cfc9212855ee88ed",
   "execution_count": 120,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df_val"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:53:59.551228800Z",
     "start_time": "2024-05-06T07:53:59.060149400Z"
    }
   },
   "id": "34a10b1cb13de8b8",
   "execution_count": 121,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df_train"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:53:59.561201800Z",
     "start_time": "2024-05-06T07:53:59.089073100Z"
    }
   },
   "id": "b6d606986613d249",
   "execution_count": 122,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df_train['client_id'].value_counts(ascending=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:53:59.643981Z",
     "start_time": "2024-05-06T07:53:59.104032500Z"
    }
   },
   "id": "2dc1f3507e88ca70",
   "execution_count": 123,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df_val['client_id'].value_counts(ascending=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:53:59.663436300Z",
     "start_time": "2024-05-06T07:53:59.118992700Z"
    }
   },
   "id": "b76854c74dcbe6ec",
   "execution_count": 124,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df_test['client_id'].value_counts(ascending=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:53:59.768824500Z",
     "start_time": "2024-05-06T07:53:59.133952300Z"
    }
   },
   "id": "b852eeccef319e18",
   "execution_count": 125,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Audio Preprocessing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "29260740840bf9d"
  },
  {
   "cell_type": "code",
   "source": [
    "df_test_filenames = df_test['path']\n",
    "df_val_filenames = df_val['path']\n",
    "df_train_filenames = df_train['path']\n",
    "df_test_filenames"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:53:59.896316200Z",
     "start_time": "2024-05-06T07:53:59.183147100Z"
    }
   },
   "id": "a8924444a65be459",
   "execution_count": 126,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:53:59.982648400Z",
     "start_time": "2024-05-06T07:53:59.199419100Z"
    }
   },
   "id": "ad8dc801a01d1723",
   "execution_count": 126,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df_val_filenames"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:54:00.029085100Z",
     "start_time": "2024-05-06T07:53:59.213382100Z"
    }
   },
   "id": "a365f15425586089",
   "execution_count": 127,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "PL_DIR = os.path.join('languages_audio', 'languages_audio_wav', 'pl', 'clips')\n",
    "PL_DIR"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:54:00.122023300Z",
     "start_time": "2024-05-06T07:53:59.228341400Z"
    }
   },
   "id": "6a0e645b674e76b8",
   "execution_count": 128,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# TEST\n",
    "df_train_filenames = df_train_filenames.apply(lambda fn: os.path.join(PL_DIR, fn))\n",
    "df_val_filenames = df_val_filenames.apply(lambda fn: os.path.join(PL_DIR, fn))\n",
    "df_test_filenames = df_test_filenames.apply(lambda fn: os.path.join(PL_DIR, fn))\n",
    "df_val_filenames"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:54:00.346820800Z",
     "start_time": "2024-05-06T07:53:59.485882300Z"
    }
   },
   "id": "48837fb6e1737922",
   "execution_count": 129,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# STARE\n",
    "# pl_dataset_train = tf.data.Dataset.from_tensor_slices(df_train_filenames.apply(lambda fn: os.path.join(PL_DIR, fn)))\n",
    "# pl_dataset_val = tf.data.Dataset.from_tensor_slices(df_val_filenames.apply(lambda fn: os.path.join(PL_DIR, fn)))\n",
    "# pl_dataset_test = tf.data.Dataset.from_tensor_slices(df_test_filenames.apply(lambda fn: os.path.join(PL_DIR, fn)))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:54:00.643397300Z",
     "start_time": "2024-05-06T07:54:00.335794Z"
    }
   },
   "id": "8152a30b0143953a",
   "execution_count": 130,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "sample_rate = 48_000\n",
    "\n",
    "def add_zeros(wav, sample_rate):\n",
    "    time_probes = wav.shape[0]\n",
    "    missing_probes_one_side = int((MIN_CLIP_DURATION/1000* sample_rate - time_probes)//2)\n",
    "    padded_tensor = tf.pad(wav.numpy(), [[missing_probes_one_side, missing_probes_one_side]])\n",
    "    return tf.convert_to_tensor(padded_tensor, dtype=tf.float32)\n",
    "\n",
    "def cut_wav(wav, sample_rate):\n",
    "    time_probes = wav.shape[0]\n",
    "    # clip_dur_in_sec = time_probes / sample_rate\n",
    "    overlap = int((time_probes - (MIN_CLIP_DURATION/1000) * sample_rate)/2) \n",
    "    cut_clip = wav[overlap:(time_probes - overlap)]\n",
    "    return tf.convert_to_tensor(cut_clip, dtype=tf.float32)\n",
    "\n",
    "def load_wav_16k_mono_and_resample(filename, fin_sam_rate=16_000):\n",
    "    file_content = tf.io.read_file(filename)\n",
    "    wav, sample_rate = tf.audio.decode_wav(file_content, desired_channels=1)\n",
    "    wav = tf.squeeze(wav, axis=-1)\n",
    "    sample_rate = tf.cast(sample_rate, dtype=tf.int32)\n",
    "    # wav = librosa.resample(wav.numpy(), orig_sr=sample_rate.numpy(), target_sr=fin_sam_rate)\n",
    "    # return wav\n",
    "    # return tf.convert_to_tensor(wav, dtype=tf.float32), sample_rate.numpy()\n",
    "    return tf.convert_to_tensor(wav, dtype=tf.float32)\n",
    "\n",
    "def load_and_align_probes(file_path):\n",
    "    wav = load_wav_16k_mono_and_resample(file_path)\n",
    "    expected_probes = int((MIN_CLIP_DURATION/1000) * sample_rate)\n",
    "    print(expected_probes)\n",
    "    current_probes = wav.shape[0]\n",
    "    print(current_probes)\n",
    "    if expected_probes > current_probes:\n",
    "        print(\"Add zeros\")\n",
    "        return add_zeros(wav, sample_rate)\n",
    "    elif expected_probes < current_probes:\n",
    "        print(\"Cut wav\")\n",
    "        return cut_wav(wav, sample_rate)\n",
    "    return tf.convert_to_tensor(wav, dtype=tf.float32)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T08:06:25.348988400Z",
     "start_time": "2024-05-06T08:06:25.238257100Z"
    }
   },
   "id": "9c8d53182f5b9bce",
   "execution_count": 146,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_align_tensors = df_train_filenames.apply(lambda filename: load_and_align_probes(filename))\n",
    "val_align_tensors = df_test_filenames.apply(lambda filename: load_and_align_probes(filename))\n",
    "test_align_tensors = df_val_filenames.apply(lambda filename: load_and_align_probes(filename))\n",
    "\n",
    "type(test_align_tensors)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T08:06:31.832973300Z",
     "start_time": "2024-05-06T08:06:29.256605700Z"
    }
   },
   "id": "59b0b2f915f9abdd",
   "execution_count": 147,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "test_align_tensors.to_list()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T08:06:33.518630900Z",
     "start_time": "2024-05-06T08:06:33.437482200Z"
    }
   },
   "id": "3500453bde18d26e",
   "execution_count": 148,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_align_dataset = tf.data.Dataset.from_tensor_slices(train_align_tensors.to_list())\n",
    "test_align_dataset = tf.data.Dataset.from_tensor_slices(val_align_tensors.to_list())\n",
    "val_align_dataset = tf.data.Dataset.from_tensor_slices(test_align_tensors.to_list())\n",
    "\n",
    "test_align_dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T08:06:35.901358200Z",
     "start_time": "2024-05-06T08:06:35.658499400Z"
    }
   },
   "id": "72b7f3fb18b5c989",
   "execution_count": 149,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_align_dataset.as_numpy_iterator().next()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T09:26:14.829923Z",
     "start_time": "2024-05-06T09:26:14.106404500Z"
    }
   },
   "id": "3b9b32aa07f7d3aa",
   "execution_count": 261,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def align_probes(wav, sample_rate):\n",
    "    # wav = load_wav_16k_mono_and_resample(file_path)\n",
    "    expected_probes = (MIN_CLIP_DURATION/1000) * sample_rate\n",
    "    print(expected_probes)\n",
    "    current_probes = wav.shape[0]\n",
    "    print(current_probes)\n",
    "    if expected_probes > current_probes:\n",
    "        print(\"Add zeros\")\n",
    "        return add_zeros(wav, sample_rate)\n",
    "    if expected_probes < current_probes:\n",
    "        print(\"Cut wav\")\n",
    "        return cut_wav(wav, sample_rate)\n",
    "    return wav\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T08:11:00.762332Z",
     "start_time": "2024-05-06T08:11:00.623579800Z"
    }
   },
   "id": "f0a38271117d59b7",
   "execution_count": 196,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "MIN_CLIP_DURATION/1000* sample_rate"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T08:11:01.478120700Z",
     "start_time": "2024-05-06T08:11:01.297316700Z"
    }
   },
   "id": "94908a310416b0f0",
   "execution_count": 199,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def increase_amplitude(wav, min_increase=2.0, max_increase=5.0):\n",
    "    increased_wav = wav * random.uniform(min_increase, max_increase)\n",
    "    return tf.convert_to_tensor(increased_wav, dtype=tf.float32)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T08:11:01.703208300Z",
     "start_time": "2024-05-06T08:11:01.625479500Z"
    }
   },
   "id": "f6111e6d7401e4a5",
   "execution_count": 200,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def normalize_audio(wav):\n",
    "    max_amplitude = tf.reduce_max(tf.abs(wav))\n",
    "    normalized_wav = wav / max_amplitude  # Normalizacja do zakresu [-1, 1]\n",
    "    return normalized_wav"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T08:11:02.857081Z",
     "start_time": "2024-05-06T08:11:02.759832900Z"
    }
   },
   "id": "bf9ffe4a7b8fc4f1",
   "execution_count": 203,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def add_noise(wav, noise_level=0.1):\n",
    "    noise = tf.random.normal(tf.shape(wav), mean=0.0, stddev=noise_level)\n",
    "    return wav + noise"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T08:11:03.948483Z",
     "start_time": "2024-05-06T08:11:03.887618Z"
    }
   },
   "id": "3d8db06681bdb844",
   "execution_count": 206,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def time_masking(wav, max_mask_length=10000):\n",
    "    # Sprawdzenie długości wav\n",
    "        # Sprawdzenie czy wav jest pusty lub ma nieprawidłowy kształt\n",
    "    if wav is None or tf.rank(wav) != 1:\n",
    "        return wav\n",
    "    \n",
    "    # Sprawdzenie długości wav\n",
    "    if tf.shape(wav)[0] <= max_mask_length:\n",
    "        return wav\n",
    "    \n",
    "    # Losowa długość maskowania\n",
    "    mask_length = tf.random.uniform([], maxval=max_mask_length, dtype=tf.int32)\n",
    "    \n",
    "    # Sprawdzenie, czy maska nie wyjdzie poza zakres\n",
    "    mask_start_max = tf.shape(wav)[0] - mask_length\n",
    "    mask_start = tf.random.uniform([], maxval=mask_start_max, dtype=tf.int32)\n",
    "    \n",
    "    # Stworzenie maski czasowej\n",
    "    mask = tf.concat([\n",
    "        tf.ones([mask_start]),\n",
    "        tf.zeros([mask_length]),\n",
    "        tf.ones([tf.shape(wav)[0] - mask_start - mask_length])\n",
    "    ], axis=0)\n",
    "    \n",
    "    # Zastosowanie maskowania do sygnału audio\n",
    "    masked_wav = wav * mask\n",
    "    \n",
    "    return masked_wav\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T08:11:04.714964700Z",
     "start_time": "2024-05-06T08:11:04.568891Z"
    }
   },
   "id": "144e847d5de32db0",
   "execution_count": 209,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def change_pitch(wav, sample_rate=48000, pitch_shift=2):\n",
    "    wav_np = wav.numpy()  # Convert tensor to numpy array\n",
    "    pitched_wav = librosa.effects.pitch_shift(wav_np, sr=sample_rate, n_steps=pitch_shift)\n",
    "    return tf.convert_to_tensor(pitched_wav, dtype=tf.float32)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T08:11:05.300260400Z",
     "start_time": "2024-05-06T08:11:05.157565500Z"
    }
   },
   "id": "81222bca1cef8ca7",
   "execution_count": 212,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def speed_up_audio(wav, speed_factor=2):\n",
    "    wav_np = wav.numpy()\n",
    "    stretched_wav = librosa.effects.time_stretch(wav_np, rate=speed_factor)   \n",
    "    return stretched_wav"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T08:11:05.949227200Z",
     "start_time": "2024-05-06T08:11:05.775089Z"
    }
   },
   "id": "67cf914574ec5490",
   "execution_count": 215,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def slow_down_audio(wav, speed_factor=0.5):\n",
    "    wav_np = wav.numpy()\n",
    "    slowed_wav_np = librosa.effects.time_stretch(wav_np, rate=speed_factor)\n",
    "    return tf.convert_to_tensor(slowed_wav_np, dtype=tf.float32)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T08:11:06.341676200Z",
     "start_time": "2024-05-06T08:11:06.227977900Z"
    }
   },
   "id": "375285678cc3b54b",
   "execution_count": 218,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "audio_processing_functions = [increase_amplitude, add_noise, time_masking, change_pitch]\n",
    "def process_random_samples(dataset, num_samples_to_process):\n",
    "    processed_samples = []\n",
    "    for _ in range(num_samples_to_process):\n",
    "        shuffled_dataset = dataset.shuffle(buffer_size=1000)\n",
    "        random_sample =  next(iter(shuffled_dataset.take(1)))\n",
    "\n",
    "        processing_function = random.choice(audio_processing_functions)\n",
    "        processed_sample = processing_function(random_sample)\n",
    "\n",
    "        processed_samples.append(processed_sample)\n",
    "\n",
    "    return processed_samples"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T08:11:07.171957900Z",
     "start_time": "2024-05-06T08:11:06.982898300Z"
    }
   },
   "id": "ac294b85a18c5c3d",
   "execution_count": 221,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "processed_samples_train = process_random_samples(train_align_dataset, TRAIN_SIZE - len(train_align_dataset))\n",
    "processed_samples_val = process_random_samples(val_align_dataset, (VAL_SIZE - len(val_align_dataset)))\n",
    "processed_samples_test = process_random_samples(test_align_dataset, (TEST_SIZE - len(test_align_dataset)))\n",
    "processed_samples_test"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T08:11:08.452451100Z",
     "start_time": "2024-05-06T08:11:08.231880800Z"
    }
   },
   "id": "3798bc6bccff9b18",
   "execution_count": 223,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "align_processed_train = [align_probes(tensor, sample_rate) for tensor in processed_samples_train]\n",
    "align_processed_val = [align_probes(tensor, sample_rate) for tensor in processed_samples_val]\n",
    "align_processed_test = [align_probes(tensor,sample_rate) for tensor in processed_samples_test]\n",
    "align_processed_train"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T08:11:09.283723100Z",
     "start_time": "2024-05-06T08:11:09.208514800Z"
    }
   },
   "id": "297274267826dace",
   "execution_count": 224,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "processed_samples_train_dataset = tf.data.Dataset.from_tensor_slices(align_processed_train)\n",
    "processed_samples_val_dataset = tf.data.Dataset.from_tensor_slices(align_processed_val)\n",
    "processed_samples_test_dataset = tf.data.Dataset.from_tensor_slices(align_processed_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T08:11:23.855876300Z",
     "start_time": "2024-05-06T08:11:23.773559Z"
    }
   },
   "id": "a789f7eef861cb4f",
   "execution_count": 225,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "processed_samples_test_dataset.as_numpy_iterator()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T08:11:28.918077500Z",
     "start_time": "2024-05-06T08:11:28.867222Z"
    }
   },
   "id": "78495d0f1138c0f",
   "execution_count": 226,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "train_dataset_con = train_align_dataset.concatenate(processed_samples_train_dataset)\n",
    "val_dataset_con = val_align_dataset.concatenate(processed_samples_val_dataset)\n",
    "test_dataset_con = test_align_dataset.concatenate(processed_samples_test_dataset)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T08:11:30.967585300Z",
     "start_time": "2024-05-06T08:11:30.891747800Z"
    }
   },
   "id": "abb91118a9271c66",
   "execution_count": 227,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "align_pl_dataset_train_with_processed_samples_norm = train_dataset_con.map(lambda audio: normalize_audio(audio))\n",
    "align_pl_dataset_val_with_processed_samples_norm = val_dataset_con.map(lambda audio: normalize_audio(audio))\n",
    "align_pl_dataset_test_with_processed_samples_norm = test_dataset_con.map(lambda audio: normalize_audio(audio))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T08:11:37.202685400Z",
     "start_time": "2024-05-06T08:11:37.108148900Z"
    }
   },
   "id": "3da5eb659b8031a4",
   "execution_count": 228,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def create_spectrogram(wav):\n",
    "    spectrogram = tf.signal.stft(wav, frame_length=320, frame_step=32)\n",
    "    spectrogram = tf.abs(spectrogram)\n",
    "    spectrogram = tf.expand_dims(spectrogram, axis=2)\n",
    "    return spectrogram"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T08:11:38.235589Z",
     "start_time": "2024-05-06T08:11:38.169111Z"
    }
   },
   "id": "e2de33c855dae8d2",
   "execution_count": 229,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "spectrogram_pl_dataset_train = align_pl_dataset_train_with_processed_samples_norm.map(lambda audio: create_spectrogram(audio))\n",
    "spectrogram_pl_dataset_val = align_pl_dataset_val_with_processed_samples_norm.map(lambda audio: create_spectrogram(audio))\n",
    "spectrogram_pl_dataset_test = align_pl_dataset_test_with_processed_samples_norm.map(lambda audio: create_spectrogram(audio))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T08:11:44.576202100Z",
     "start_time": "2024-05-06T08:11:44.359674400Z"
    }
   },
   "id": "994ed2ed4ea1fe63",
   "execution_count": 232,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "spectrogram_pl_dataset_train"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T08:11:45.828427700Z",
     "start_time": "2024-05-06T08:11:45.757206600Z"
    }
   },
   "id": "91ece8457ac62112",
   "execution_count": 233,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "spectrogram_pl_dataset_val"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T08:14:37.943709900Z",
     "start_time": "2024-05-06T08:14:37.833976600Z"
    }
   },
   "id": "d1e27210b5266e61",
   "execution_count": 238,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "spectrogram_pl_dataset_test"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T08:11:47.795593200Z",
     "start_time": "2024-05-06T08:11:47.722695700Z"
    }
   },
   "id": "26b97f35b8ad06f9",
   "execution_count": 235,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "spectrogram_pl_dataset_test.as_numpy_iterator().next().shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T08:17:05.320321300Z",
     "start_time": "2024-05-06T08:17:05.170490400Z"
    }
   },
   "id": "a896f7d090b76e59",
   "execution_count": 243,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "labeled_train_dataset = tf.data.Dataset.zip((spectrogram_pl_dataset_train, tf.data.Dataset.from_tensor_slices(tf.ones(len(spectrogram_pl_dataset_train)))))\n",
    "labeled_val_dataset = tf.data.Dataset.zip((spectrogram_pl_dataset_val, tf.data.Dataset.from_tensor_slices(tf.ones(len(spectrogram_pl_dataset_val)))))\n",
    "labeled_test_dataset = tf.data.Dataset.zip((spectrogram_pl_dataset_test, tf.data.Dataset.from_tensor_slices(tf.ones(len(spectrogram_pl_dataset_test)))))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T08:24:02.493423500Z",
     "start_time": "2024-05-06T08:24:02.377539Z"
    }
   },
   "id": "6d46c6b640e6deaa",
   "execution_count": 257,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "labeled_train_dataset.as_numpy_iterator().next()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T08:24:02.847373200Z",
     "start_time": "2024-05-06T08:24:02.675831800Z"
    }
   },
   "id": "5b930513b2d2ebfb",
   "execution_count": 258,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "labeled_val_dataset.as_numpy_iterator().next()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T08:24:03.146333300Z",
     "start_time": "2024-05-06T08:24:02.992217400Z"
    }
   },
   "id": "1fd73f0fbab8bea5",
   "execution_count": 259,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "labeled_test_dataset.as_numpy_iterator().next()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T08:24:03.895592300Z",
     "start_time": "2024-05-06T08:24:03.758940200Z"
    }
   },
   "id": "ddbc512a5fc9f74f",
   "execution_count": 260,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "568c51f7709b2f9b",
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
