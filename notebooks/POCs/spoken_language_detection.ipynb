{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Spoken language detection"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d758a0066910796d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7b90391470eb7da4"
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import IPython"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:41.187422Z",
     "start_time": "2024-05-06T07:33:37.728260Z"
    }
   },
   "id": "e771baad4b9578e9",
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "PL_LANG_FILE = os.path.join('languages_audio', 'languages_audio_wav', 'pl', 'clips', 'common_voice_pl_20547814.wav')\n",
    "PL_LANG_FILE"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:41.202412400Z",
     "start_time": "2024-05-06T07:33:41.171205600Z"
    }
   },
   "id": "ff173514fa44dc8c",
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "file_content = tf.io.read_file(PL_LANG_FILE) # Load encoded wav file\n",
    "type(file_content)\n",
    "   "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:41.338960500Z",
     "start_time": "2024-05-06T07:33:41.186424500Z"
    }
   },
   "id": "2b028d34d63a7a96",
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "wav, sample_rate = tf.audio.decode_wav(file_content, desired_channels=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:41.352946Z",
     "start_time": "2024-05-06T07:33:41.219123500Z"
    }
   },
   "id": "eec2aff63ff570e7",
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "wav"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:41.358907800Z",
     "start_time": "2024-05-06T07:33:41.234614500Z"
    }
   },
   "id": "165d2a15e32cef71",
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "sample_rate.numpy() # 48 kHz próbkowanie należy zmienic"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:41.428860100Z",
     "start_time": "2024-05-06T07:33:41.249201300Z"
    }
   },
   "id": "a55378046eb58345",
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "wav = tf.squeeze(wav, axis=-1) # axis=-1 żeby usunąć ostatni wymiar który jest równy 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:41.432849300Z",
     "start_time": "2024-05-06T07:33:41.266155800Z"
    }
   },
   "id": "88b380d62e019e07",
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "wav"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:41.455790500Z",
     "start_time": "2024-05-06T07:33:41.280117800Z"
    }
   },
   "id": "57c70d55bd4597f2",
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "wav = librosa.resample(wav.numpy(), orig_sr=sample_rate.numpy(), target_sr=16_000)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:43.854193900Z",
     "start_time": "2024-05-06T07:33:41.298094900Z"
    }
   },
   "id": "7ba2527067b02b9c",
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "wav = tf.convert_to_tensor(wav, dtype=tf.float32)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:43.876110700Z",
     "start_time": "2024-05-06T07:33:43.858159200Z"
    }
   },
   "id": "4de52491185a80ff",
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "wav_example = wav\n",
    "wav_example"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:43.943522600Z",
     "start_time": "2024-05-06T07:33:43.872120800Z"
    }
   },
   "id": "a7e82a11e0c0b809",
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "plt.plot(wav)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:44.097677400Z",
     "start_time": "2024-05-06T07:33:43.888089700Z"
    }
   },
   "id": "20d348d5ad389a67",
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "IPython.display.Audio(PL_LANG_FILE)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:44.263425Z",
     "start_time": "2024-05-06T07:33:44.093137300Z"
    }
   },
   "id": "8622964d5e5d569c",
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. Create Dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "34f0cc05b1a0cb20"
  },
  {
   "cell_type": "code",
   "source": [
    "PL_DIR = os.path.join('languages_audio', 'languages_audio_wav', 'pl', 'clips')\n",
    "PL_DIR"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:44.344427Z",
     "start_time": "2024-05-06T07:33:44.251874400Z"
    }
   },
   "id": "4343ebee9c38ae63",
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# create tensorflow dataset\n",
    "pl_dataset = tf.data.Dataset.list_files(PL_DIR + '\\*.wav')\n",
    "pl_dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:45.693103100Z",
     "start_time": "2024-05-06T07:33:44.264421600Z"
    }
   },
   "id": "ba1dbf66c6eda4bf",
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "pl_dataset.as_numpy_iterator().next()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:45.809880600Z",
     "start_time": "2024-05-06T07:33:45.688106Z"
    }
   },
   "id": "9a641093a2c580c2",
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "pl_dataset.as_numpy_iterator().next()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:45.926236300Z",
     "start_time": "2024-05-06T07:33:45.810878200Z"
    }
   },
   "id": "88e49cfbfba3bafb",
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df = pd.read_csv(os.path.join('languages_audio', 'languages_audio_mp3', 'pl', 'validated.tsv'), sep='\\t')\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:46.430140800Z",
     "start_time": "2024-05-06T07:33:45.921249500Z"
    }
   },
   "id": "b25c7c351f5d432",
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df[df['gender'] == 'female_feminine']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:46.468608100Z",
     "start_time": "2024-05-06T07:33:46.421165500Z"
    }
   },
   "id": "a419164919440f40",
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df[df['gender'] == 'male_masculine']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:46.577530500Z",
     "start_time": "2024-05-06T07:33:46.453076300Z"
    }
   },
   "id": "6c0ecc7926645f66",
   "execution_count": 20,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df.groupby('sentence_id').count()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:46.699975900Z",
     "start_time": "2024-05-06T07:33:46.483172400Z"
    }
   },
   "id": "805a0e99ad4a6f32",
   "execution_count": 21,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df['sentence_id'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:46.793301500Z",
     "start_time": "2024-05-06T07:33:46.576533400Z"
    }
   },
   "id": "3765e7a31c9a897d",
   "execution_count": 22,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df['sentence_id'].nunique()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:46.797290900Z",
     "start_time": "2024-05-06T07:33:46.609445200Z"
    }
   },
   "id": "91c679c99c892a10",
   "execution_count": 23,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df['client_id'].value_counts().sort_values(ascending=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:46.820262400Z",
     "start_time": "2024-05-06T07:33:46.657317100Z"
    }
   },
   "id": "fedb03302fc130ee",
   "execution_count": 24,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:46.889046600Z",
     "start_time": "2024-05-06T07:33:46.670282300Z"
    }
   },
   "id": "a8d7ac801357330b",
   "execution_count": 24,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df[['sentence_id', 'client_id']].groupby(by='sentence_id').count().sort_values(by='client_id', ascending=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:46.953059100Z",
     "start_time": "2024-05-06T07:33:46.686995600Z"
    }
   },
   "id": "b66628d65d38615e",
   "execution_count": 25,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df[['client_id', 'sentence_id']].sort_values(by='client_id', ascending=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:47.151617400Z",
     "start_time": "2024-05-06T07:33:46.765377300Z"
    }
   },
   "id": "788ead3deb0c642a",
   "execution_count": 26,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df[['client_id', 'sentence_id']].sort_values(by='client_id', ascending=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:47.162588500Z",
     "start_time": "2024-05-06T07:33:46.828209Z"
    }
   },
   "id": "54720b0b0d5e35f9",
   "execution_count": 27,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df[df['client_id'] == 'ffffc00a5ed69f08a486837064ec2caeff21fe06264c3dd733f633fb6c2ae9aeb561a5a6f43e000554d4b3cc171644ba4ce971177af1cb54f9bd8cc153e71a5c']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:47.185174300Z",
     "start_time": "2024-05-06T07:33:46.890044600Z"
    }
   },
   "id": "28a7c157bc223a7",
   "execution_count": 28,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# # sprawdzenie czy client_id oraz sequence_id się nie duplikują (czy jeden klient ma rózne sekwencej)\n",
    "# \n",
    "# for client_id in df['client_id'].unique():\n",
    "#     sentence_count = df['sentence_id'][df['client_id']  == client_id].count()\n",
    "#     client_id_count = df['client_id'][df['client_id']  == client_id].value_counts().iloc[0]\n",
    "#     if sentence_count != client_id_count:\n",
    "#         print(True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:47.211104800Z",
     "start_time": "2024-05-06T07:33:46.922955800Z"
    }
   },
   "id": "59ec3f2d2259223d",
   "execution_count": 29,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df['sentence_id'][df['client_id']  == 'ffffc00a5ed69f08a486837064ec2caeff21fe06264c3dd733f633fb6c2ae9aeb561a5a6f43e000554d4b3cc171644ba4ce971177af1cb54f9bd8cc153e71a5c'].count()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:47.281915900Z",
     "start_time": "2024-05-06T07:33:46.938947400Z"
    }
   },
   "id": "589f00618f423817",
   "execution_count": 30,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df['client_id'][df['client_id']  == 'ffffc00a5ed69f08a486837064ec2caeff21fe06264c3dd733f633fb6c2ae9aeb561a5a6f43e000554d4b3cc171644ba4ce971177af1cb54f9bd8cc153e71a5c'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:47.368904300Z",
     "start_time": "2024-05-06T07:33:46.955053100Z"
    }
   },
   "id": "833e078c9b16e7e2",
   "execution_count": 31,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# TODO: WZiąć plik validated.tsv nastepnie podzielić go na mężczyzn i kobiety (dwa osobne dataset) [DONE]. następnie wrzucać do każdego ze zbiorów (najpiew testwoy, walidacyjny, treningowy) client_id od najmniejszej liczby wystąpień w obydwu  dopasować czas trwania każdej próbki (najpierw obcinać od środka, potem dopełniać zerami), zmienić na spektogram i dopiero wtedy dodać (koniec funkcji). druga funkcja będzie jako augumentowanie losowych danych (losowo wybiera funkcję która coś zrobi z danymi) jeżeli moje zbiory kobiet i mężczyzn nie będą spełniały wymaganej ilości próbek którą się poda. Na wyjściu ma być tensor z próbkami spektogramu. To zrobić finalnie dla każdego folderu (języka). Wtedy dopiero dodać label w formie one hot encoding"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:47.372894100Z",
     "start_time": "2024-05-06T07:33:46.970520800Z"
    }
   },
   "id": "b41eb727ab7bcbf8",
   "execution_count": 32,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load data:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d07b8080fb6705c7"
  },
  {
   "cell_type": "code",
   "source": [
    "df = pd.read_csv(os.path.join('languages_audio', 'languages_audio_mp3', 'pl', 'validated.tsv'), sep='\\t', usecols=['client_id', 'path', 'sentence_id', 'gender', 'locale'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:47.653442500Z",
     "start_time": "2024-05-06T07:33:46.986476500Z"
    }
   },
   "id": "1ba578e1c67f2d8d",
   "execution_count": 33,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Change mp3 to wav name"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8f69ec6d7189b945"
  },
  {
   "cell_type": "code",
   "source": [
    "df = df.apply(lambda path: path.str.replace('.mp3', '.wav'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:47.851971400Z",
     "start_time": "2024-05-06T07:33:47.390823Z"
    }
   },
   "id": "9422e72ec897347b",
   "execution_count": 34,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Split to woman and man sets"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e3481591ddd6b352"
  },
  {
   "cell_type": "code",
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:47.864008900Z",
     "start_time": "2024-05-06T07:33:47.529339100Z"
    }
   },
   "id": "437897c4a0dd254f",
   "execution_count": 35,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "woman_filter = df['gender'] == 'female_feminine'\n",
    "man_filter = df['gender'] == 'male_masculine'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:47.940794900Z",
     "start_time": "2024-05-06T07:33:47.545321Z"
    }
   },
   "id": "5ea864f56b635651",
   "execution_count": 36,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df_women = df[woman_filter]\n",
    "df_women"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:47.945780900Z",
     "start_time": "2024-05-06T07:33:47.560129400Z"
    }
   },
   "id": "283bff5acfcbbefb",
   "execution_count": 37,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df_men = df[man_filter]\n",
    "df_men"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:47.981302700Z",
     "start_time": "2024-05-06T07:33:47.577082800Z"
    }
   },
   "id": "d227f88872caa27c",
   "execution_count": 38,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Set number of probes in my set and split it to train, validate and test"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bf90c16bcfef86e1"
  },
  {
   "cell_type": "code",
   "source": [
    "SET_SIZE = 50_000\n",
    "MAX_NUMBER_OF_CLIENT_ID = 3000\n",
    "MIN_CLIP_DURATION = 4000 #  clip time in [ms]\n",
    "\n",
    "TRAIN_SIZE = int(SET_SIZE * 0.6)\n",
    "VAL_SIZE = int((SET_SIZE - TRAIN_SIZE) // 2)\n",
    "TEST_SIZE = SET_SIZE - TRAIN_SIZE - VAL_SIZE\n",
    "\n",
    "print(f'Train size: {TRAIN_SIZE}')\n",
    "print(f'Validation size: {VAL_SIZE}')\n",
    "print(f'Test size: {TEST_SIZE}')\n",
    "print(f'Sum of sizes: {TRAIN_SIZE + VAL_SIZE + TEST_SIZE} is equal to SET_SIZE {TRAIN_SIZE + VAL_SIZE + TEST_SIZE == SET_SIZE}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:48.016202Z",
     "start_time": "2024-05-06T07:33:47.593040900Z"
    }
   },
   "id": "73b6742e55cd46ce",
   "execution_count": 39,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Select probes with min that time \n",
    "df_clips_duration = pd.read_csv(os.path.join('languages_audio', 'languages_audio_mp3', 'pl', 'clip_durations.tsv'), sep='\\t')\n",
    "df_clips_duration['clip'] = df_clips_duration['clip'].apply(lambda clip: clip.replace('.mp3', '.wav'))\n",
    "df_men = df_men.merge(df_clips_duration, left_on='path', right_on='clip')\n",
    "df_men"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:48.122097100Z",
     "start_time": "2024-05-06T07:33:47.614575900Z"
    }
   },
   "id": "2bc35c9fa1f2a04a",
   "execution_count": 40,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "# \n",
    "# for i in range(len(df_clips_duration)):\n",
    "#     print(i)\n",
    "#     row_in_df = df_men[df_men['path']== df_clips_duration.iloc[i]['clip']] \n",
    "#     if (df_clips_duration.iloc[i]['duration[ms]'] >= MIN_CLIP_DURATION) and (len(row_in_df) >= 0):\n",
    "#         rows_over_min_dur_time = pd.concat([rows_over_min_dur_time, row_in_df])\n",
    "#     else:\n",
    "#         rows_under_min_dur_time = pd.concat([rows_under_min_dur_time, row_in_df])\n",
    "# \n",
    "# \n",
    "\n",
    "rows_over_min_dur_time = df_men[df_men['duration[ms]'] >= MIN_CLIP_DURATION]\n",
    "rows_under_min_dur_time = df_men[df_men['duration[ms]'] < MIN_CLIP_DURATION]\n",
    "rows_over_min_dur_time"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:48.227424200Z",
     "start_time": "2024-05-06T07:33:47.812206600Z"
    }
   },
   "id": "a901ecef326bfb2e",
   "execution_count": 41,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "rows_under_min_dur_time"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:48.247439900Z",
     "start_time": "2024-05-06T07:33:47.842995100Z"
    }
   },
   "id": "2fe7b8e7b0273d45",
   "execution_count": 42,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "if len(rows_over_min_dur_time) >= SET_SIZE:\n",
    "    df_men = rows_over_min_dur_time\n",
    "else:\n",
    "    df_men = pd.concat([rows_over_min_dur_time, rows_under_min_dur_time], ignore_index=True)[:SET_SIZE]\n",
    "\n",
    "df_men"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:48.294823900Z",
     "start_time": "2024-05-06T07:33:47.855960900Z"
    }
   },
   "id": "3a4ae1c66f24659e",
   "execution_count": 43,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df_train = pd.DataFrame()\n",
    "df_val = pd.DataFrame()\n",
    "df_test = pd.DataFrame()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:48.299407100Z",
     "start_time": "2024-05-06T07:33:47.904899900Z"
    }
   },
   "id": "94f0a7c187961064",
   "execution_count": 44,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df_counted_id = df_men['client_id'].value_counts(ascending=True)\n",
    "df_counted_id"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:48.404381100Z",
     "start_time": "2024-05-06T07:33:47.921853600Z"
    }
   },
   "id": "6219cdc9196dd3c8",
   "execution_count": 45,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "clients_form_origin_df = df_men[df_men['client_id'] == df_counted_id.index[200]]\n",
    "clients_form_origin_df1 = df_men[df_men['client_id'] == df_counted_id.index[201]]\n",
    "clients_form_origin_df1['client_id'].iloc[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:48.463566Z",
     "start_time": "2024-05-06T07:33:47.936814700Z"
    }
   },
   "id": "b9d38e4396a58bfc",
   "execution_count": 46,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# df_test = pd.concat([df_test, clients_form_origin_df], ignore_index=True)\n",
    "# df_test = pd.concat([df_test, clients_form_origin_df1], ignore_index=True)\n",
    "# df_test"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:48.511459700Z",
     "start_time": "2024-05-06T07:33:47.950739300Z"
    }
   },
   "id": "398c94c683a2fe41",
   "execution_count": 47,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "for i in range(len(df_counted_id)):\n",
    "    print(df_counted_id.index[i], df_counted_id.iloc[i])\n",
    "    rows_form_origin_df = df_men[df_men['client_id'] == df_counted_id.index[i]][:MAX_NUMBER_OF_CLIENT_ID]\n",
    "    if len(rows_form_origin_df) <= (TEST_SIZE - len(df_test)) and rows_form_origin_df['client_id'].iloc[0] not in df_test:\n",
    "        df_test = pd.concat([df_test, rows_form_origin_df], ignore_index=True)\n",
    "        continue\n",
    "    if len(rows_form_origin_df) <= (VAL_SIZE - len(df_val)):\n",
    "        df_val = pd.concat([df_val, rows_form_origin_df], ignore_index=True)\n",
    "        continue\n",
    "    if len(rows_form_origin_df) <= (TRAIN_SIZE - len(df_train)):\n",
    "        df_train = pd.concat([df_train, rows_form_origin_df], ignore_index=True)\n",
    "        continue\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:50.107791300Z",
     "start_time": "2024-05-06T07:33:48.003210500Z"
    }
   },
   "id": "537212501acba841",
   "execution_count": 48,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df_test"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:50.152206Z",
     "start_time": "2024-05-06T07:33:50.106765100Z"
    }
   },
   "id": "cfc9212855ee88ed",
   "execution_count": 49,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df_val"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:50.199869600Z",
     "start_time": "2024-05-06T07:33:50.121725500Z"
    }
   },
   "id": "34a10b1cb13de8b8",
   "execution_count": 50,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df_train"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:50.231662400Z",
     "start_time": "2024-05-06T07:33:50.137245800Z"
    }
   },
   "id": "b6d606986613d249",
   "execution_count": 51,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df_train['client_id'].value_counts(ascending=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:50.258590900Z",
     "start_time": "2024-05-06T07:33:50.154200500Z"
    }
   },
   "id": "2dc1f3507e88ca70",
   "execution_count": 52,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df_val['client_id'].value_counts(ascending=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:50.306471800Z",
     "start_time": "2024-05-06T07:33:50.169160700Z"
    }
   },
   "id": "b76854c74dcbe6ec",
   "execution_count": 53,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df_test['client_id'].value_counts(ascending=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:50.373295900Z",
     "start_time": "2024-05-06T07:33:50.184676200Z"
    }
   },
   "id": "b852eeccef319e18",
   "execution_count": 54,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Audio Preprocessing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "29260740840bf9d"
  },
  {
   "cell_type": "code",
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:50.408627900Z",
     "start_time": "2024-05-06T07:33:50.200867100Z"
    }
   },
   "id": "b5266bd11b101c85",
   "execution_count": 54,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:50.427618500Z",
     "start_time": "2024-05-06T07:33:50.217387800Z"
    }
   },
   "id": "e5eb4e2ce3a79b64",
   "execution_count": 54,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df_test_filenames = df_test['path']\n",
    "df_val_filenames = df_val['path']\n",
    "df_train_filenames = df_train['path']\n",
    "df_test_filenames"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:50.447523900Z",
     "start_time": "2024-05-06T07:33:50.232661400Z"
    }
   },
   "id": "a8924444a65be459",
   "execution_count": 55,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:50.459514100Z",
     "start_time": "2024-05-06T07:33:50.247620100Z"
    }
   },
   "id": "ad8dc801a01d1723",
   "execution_count": 55,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df_val_filenames"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:50.540970900Z",
     "start_time": "2024-05-06T07:33:50.264575700Z"
    }
   },
   "id": "a365f15425586089",
   "execution_count": 56,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "PL_DIR = os.path.join('languages_audio', 'languages_audio_wav', 'pl', 'clips')\n",
    "PL_DIR"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:50.610191200Z",
     "start_time": "2024-05-06T07:33:50.279544500Z"
    }
   },
   "id": "6a0e645b674e76b8",
   "execution_count": 57,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# TEST\n",
    "df_train_filenames = df_train_filenames.apply(lambda fn: os.path.join(PL_DIR, fn))\n",
    "df_val_filenames = df_val_filenames.apply(lambda fn: os.path.join(PL_DIR, fn))\n",
    "df_test_filenames = df_test_filenames.apply(lambda fn: os.path.join(PL_DIR, fn))\n",
    "df_val_filenames"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:50.776095800Z",
     "start_time": "2024-05-06T07:33:50.294503800Z"
    }
   },
   "id": "48837fb6e1737922",
   "execution_count": 58,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# STARE\n",
    "pl_dataset_train = tf.data.Dataset.from_tensor_slices(df_train_filenames.apply(lambda fn: os.path.join(PL_DIR, fn)))\n",
    "pl_dataset_val = tf.data.Dataset.from_tensor_slices(df_val_filenames.apply(lambda fn: os.path.join(PL_DIR, fn)))\n",
    "pl_dataset_test = tf.data.Dataset.from_tensor_slices(df_test_filenames.apply(lambda fn: os.path.join(PL_DIR, fn)))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:50.860545200Z",
     "start_time": "2024-05-06T07:33:50.403641500Z"
    }
   },
   "id": "8152a30b0143953a",
   "execution_count": 59,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# def load_and_align_probes(file_path):\n",
    "#     wav = load_wav_16k_mono_and_resample(file_path)\n",
    "#     expected_probes = int((MIN_CLIP_DURATION/1000) * sample_rate)\n",
    "#     print(expected_probes)\n",
    "#     current_probes = wav.shape[0]\n",
    "#     print(current_probes)\n",
    "#     if expected_probes > current_probes:\n",
    "#         print(\"Add zeros\")\n",
    "#         wav = add_zeros(wav, sample_rate)\n",
    "#     elif expected_probes < current_probes:\n",
    "#         print(\"Cut wav\")\n",
    "#         wav = cut_wav(wav, sample_rate)\n",
    "#     return tf.convert_to_tensor(wav, dtype=tf.float32)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:50.865532Z",
     "start_time": "2024-05-06T07:33:50.515281500Z"
    }
   },
   "id": "9c8d53182f5b9bce",
   "execution_count": 60,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# test_align_tensors = df_test_filenames[:5].apply(lambda filename: load_and_align_probes(filename))\n",
    "# test_align_tensors"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:50.886926600Z",
     "start_time": "2024-05-06T07:33:50.529504900Z"
    }
   },
   "id": "59b0b2f915f9abdd",
   "execution_count": 61,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# test_align_tensors.to_list()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:50.909865400Z",
     "start_time": "2024-05-06T07:33:50.544929700Z"
    }
   },
   "id": "3500453bde18d26e",
   "execution_count": 62,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# test_align_dataset = tf.data.Dataset.from_tensor_slices(test_align_tensors.to_list())\n",
    "# test_align_dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:50.913874500Z",
     "start_time": "2024-05-06T07:33:50.559915300Z"
    }
   },
   "id": "72b7f3fb18b5c989",
   "execution_count": 63,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# test_align_dataset.as_numpy_iterator().next()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:50.917864Z",
     "start_time": "2024-05-06T07:33:50.577866600Z"
    }
   },
   "id": "f29b31a21a5a43f",
   "execution_count": 64,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# pl_dataset_test.as_numpy_iterator().next()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:50.922830400Z",
     "start_time": "2024-05-06T07:33:50.592660600Z"
    }
   },
   "id": "3b9b32aa07f7d3aa",
   "execution_count": 65,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "sample_rate = 48_000\n",
    "\n",
    "def load_wav_16k_mono_and_resample(filename, fin_sam_rate=16_000):\n",
    "    file_content = tf.io.read_file(filename)\n",
    "    wav, sample_rate = tf.audio.decode_wav(file_content, desired_channels=1)\n",
    "    wav = tf.squeeze(wav, axis=-1)\n",
    "    sample_rate = tf.cast(sample_rate, dtype=tf.int32)\n",
    "    # wav = librosa.resample(wav.numpy(), orig_sr=sample_rate.numpy(), target_sr=fin_sam_rate)\n",
    "    # return wav\n",
    "    return tf.convert_to_tensor(wav, dtype=tf.float32)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:50.954045600Z",
     "start_time": "2024-05-06T07:33:50.609223300Z"
    }
   },
   "id": "74fc56cd91f429b6",
   "execution_count": 66,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "clip = load_wav_16k_mono_and_resample(df_train_filenames[0])\n",
    "print(clip)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:50.959031500Z",
     "start_time": "2024-05-06T07:33:50.623157100Z"
    }
   },
   "id": "332b30daf7ac6565",
   "execution_count": 67,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "plt.plot(clip)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:51.122283200Z",
     "start_time": "2024-05-06T07:33:50.654074100Z"
    }
   },
   "id": "e4126cb478068b07",
   "execution_count": 68,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def cut_wav(wav, sample_rate):\n",
    "    time_probes = wav.shape[0]\n",
    "    # clip_dur_in_sec = time_probes / sample_rate\n",
    "    overlap = int((time_probes - (MIN_CLIP_DURATION/1000) * sample_rate)/2) \n",
    "    cut_clip = wav[overlap:(time_probes - overlap)]\n",
    "    return tf.convert_to_tensor(cut_clip, dtype=tf.float32)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:51.127246700Z",
     "start_time": "2024-05-06T07:33:50.828201400Z"
    }
   },
   "id": "9d7b8d2e634efd0c",
   "execution_count": 69,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "cut_clip = cut_wav(clip, sample_rate)\n",
    "cut_clip"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:51.157154500Z",
     "start_time": "2024-05-06T07:33:50.842163800Z"
    }
   },
   "id": "c52232a7a4c99edc",
   "execution_count": 70,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def add_zeros(wav, sample_rate):\n",
    "    time_probes = wav.shape[0]\n",
    "    missing_probes_one_side = int((MIN_CLIP_DURATION/1000* sample_rate - time_probes)//2)\n",
    "    padded_tensor = tf.pad(wav.numpy(), [[missing_probes_one_side, missing_probes_one_side]])\n",
    "    return tf.convert_to_tensor(padded_tensor, dtype=tf.float32)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:51.183108Z",
     "start_time": "2024-05-06T07:33:50.857552800Z"
    }
   },
   "id": "4e3c544f4d65a07b",
   "execution_count": 71,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "add_zeros(wav[:30000], sample_rate)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:51.217025700Z",
     "start_time": "2024-05-06T07:33:50.873962300Z"
    }
   },
   "id": "f8c23dfa6824185f",
   "execution_count": 72,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def align_probes(wav, sample_rate):\n",
    "    # wav = load_wav_16k_mono_and_resample(file_path)\n",
    "    expected_probes = int((MIN_CLIP_DURATION/1000) * sample_rate)\n",
    "    print(expected_probes)\n",
    "    current_probes = wav.shape[0]\n",
    "    print(current_probes)\n",
    "    if expected_probes > current_probes:\n",
    "        print(\"Add zeros\")\n",
    "        wav = add_zeros(wav, sample_rate)\n",
    "    elif expected_probes < current_probes:\n",
    "        print(\"Cut wav\")\n",
    "        wav = cut_wav(wav, sample_rate)\n",
    "    return wav\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:51.221011400Z",
     "start_time": "2024-05-06T07:33:50.889918600Z"
    }
   },
   "id": "a1a3a38e611098fa",
   "execution_count": 73,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# def align_probes(file_path):\n",
    "#     wav = load_wav_16k_mono_and_resample(file_path)\n",
    "#     expected_probes = (MIN_CLIP_DURATION/1000) * sample_rate\n",
    "#     print(expected_probes)\n",
    "#     current_probes = wav.shape[0]\n",
    "#     print(current_probes)\n",
    "#     if expected_probes > current_probes:\n",
    "#         print(\"Add zeros\")\n",
    "#         return add_zeros(wav, sample_rate)\n",
    "#     if expected_probes < current_probes:\n",
    "#         print(\"Cut wav\")\n",
    "#         return cut_wav(wav, sample_rate)\n",
    "    \n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:51.261876800Z",
     "start_time": "2024-05-06T07:33:50.905896200Z"
    }
   },
   "id": "f0a38271117d59b7",
   "execution_count": 74,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "a = align_probes(cut_clip, sample_rate)\n",
    "a"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:51.269855300Z",
     "start_time": "2024-05-06T07:33:50.921833400Z"
    }
   },
   "id": "512bed33b954ac1b",
   "execution_count": 75,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "plt.plot(a)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:51.310979800Z",
     "start_time": "2024-05-06T07:33:50.935611600Z"
    }
   },
   "id": "833a1827f53bab24",
   "execution_count": 76,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "MIN_CLIP_DURATION/1000* sample_rate"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:51.315937700Z",
     "start_time": "2024-05-06T07:33:51.109323600Z"
    }
   },
   "id": "94908a310416b0f0",
   "execution_count": 77,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def increase_amplitude(wav, min_increase=2.0, max_increase=5.0):\n",
    "    increased_wav = wav * random.uniform(min_increase, max_increase)\n",
    "    return tf.convert_to_tensor(increased_wav, dtype=tf.float32)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:51.499187500Z",
     "start_time": "2024-05-06T07:33:51.123257600Z"
    }
   },
   "id": "f6111e6d7401e4a5",
   "execution_count": 78,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "inc_a = increase_amplitude(a)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:51.503148700Z",
     "start_time": "2024-05-06T07:33:51.139207200Z"
    }
   },
   "id": "13b5b423041d6406",
   "execution_count": 79,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "plt.plot(inc_a)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:51.680164300Z",
     "start_time": "2024-05-06T07:33:51.155159400Z"
    }
   },
   "id": "4a0ea63485d7a556",
   "execution_count": 80,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def normalize_audio(wav):\n",
    "    max_amplitude = tf.reduce_max(tf.abs(wav))\n",
    "    normalized_wav = wav / max_amplitude  # Normalizacja do zakresu [-1, 1]\n",
    "    return normalized_wav"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:51.685151100Z",
     "start_time": "2024-05-06T07:33:51.437732300Z"
    }
   },
   "id": "bf9ffe4a7b8fc4f1",
   "execution_count": 81,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "norm_a = normalize_audio(inc_a)\n",
    "norm_a"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:51.751324600Z",
     "start_time": "2024-05-06T07:33:51.452410500Z"
    }
   },
   "id": "80637b546ad63eaa",
   "execution_count": 82,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "plt.plot(norm_a)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:51.812326300Z",
     "start_time": "2024-05-06T07:33:51.483176500Z"
    }
   },
   "id": "8a643966aa163e7e",
   "execution_count": 83,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def add_noise(wav, noise_level=0.1):\n",
    "    noise = tf.random.normal(tf.shape(wav), mean=0.0, stddev=noise_level)\n",
    "    return wav + noise"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:51.816343900Z",
     "start_time": "2024-05-06T07:33:51.654234300Z"
    }
   },
   "id": "3d8db06681bdb844",
   "execution_count": 84,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "noise_a = add_noise(inc_a)\n",
    "noise_a"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:51.838284900Z",
     "start_time": "2024-05-06T07:33:51.668197300Z"
    }
   },
   "id": "4ec03f2959eaaafe",
   "execution_count": 85,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "plt.plot(noise_a)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:52.044299100Z",
     "start_time": "2024-05-06T07:33:51.685151100Z"
    }
   },
   "id": "81bca0c6340eeca9",
   "execution_count": 86,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def time_masking(wav, max_mask_length=10000):\n",
    "    # Sprawdzenie długości wav\n",
    "        # Sprawdzenie czy wav jest pusty lub ma nieprawidłowy kształt\n",
    "    if wav is None or tf.rank(wav) != 1:\n",
    "        return wav\n",
    "    \n",
    "    # Sprawdzenie długości wav\n",
    "    if tf.shape(wav)[0] <= max_mask_length:\n",
    "        return wav\n",
    "    \n",
    "    # Losowa długość maskowania\n",
    "    mask_length = tf.random.uniform([], maxval=max_mask_length, dtype=tf.int32)\n",
    "    \n",
    "    # Sprawdzenie, czy maska nie wyjdzie poza zakres\n",
    "    mask_start_max = tf.shape(wav)[0] - mask_length\n",
    "    mask_start = tf.random.uniform([], maxval=mask_start_max, dtype=tf.int32)\n",
    "    \n",
    "    # Stworzenie maski czasowej\n",
    "    mask = tf.concat([\n",
    "        tf.ones([mask_start]),\n",
    "        tf.zeros([mask_length]),\n",
    "        tf.ones([tf.shape(wav)[0] - mask_start - mask_length])\n",
    "    ], axis=0)\n",
    "    \n",
    "    # Zastosowanie maskowania do sygnału audio\n",
    "    masked_wav = wav * mask\n",
    "    \n",
    "    return masked_wav\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:52.048313100Z",
     "start_time": "2024-05-06T07:33:51.921423100Z"
    }
   },
   "id": "144e847d5de32db0",
   "execution_count": 87,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "masked_a = time_masking(inc_a, max_mask_length=50000)\n",
    "masked_a"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:52.121805100Z",
     "start_time": "2024-05-06T07:33:51.935385100Z"
    }
   },
   "id": "a6a859ef4820bb8d",
   "execution_count": 88,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "plt.plot(masked_a)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:52.189653700Z",
     "start_time": "2024-05-06T07:33:51.967419200Z"
    }
   },
   "id": "a30448e4574b193",
   "execution_count": 89,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def change_pitch(wav, sample_rate=48000, pitch_shift=2):\n",
    "    wav_np = wav.numpy()  # Convert tensor to numpy array\n",
    "    pitched_wav = librosa.effects.pitch_shift(wav_np, sr=sample_rate, n_steps=pitch_shift)\n",
    "    return tf.convert_to_tensor(pitched_wav, dtype=tf.float32)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:52.211592Z",
     "start_time": "2024-05-06T07:33:52.121805100Z"
    }
   },
   "id": "81222bca1cef8ca7",
   "execution_count": 90,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "pitch_a = change_pitch(inc_a, sample_rate)\n",
    "pitch_a"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:52.814378500Z",
     "start_time": "2024-05-06T07:33:52.135767500Z"
    }
   },
   "id": "37a0ee55cb4c3ae0",
   "execution_count": 91,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "plt.plot(pitch_a)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:52.986433800Z",
     "start_time": "2024-05-06T07:33:52.814378500Z"
    }
   },
   "id": "5f2ed133e7875796",
   "execution_count": 92,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def speed_up_audio(wav, speed_factor=2):\n",
    "    # Pobierz tablicę numpy z tensora Tensorflow\n",
    "    wav_np = wav.numpy()\n",
    "    \n",
    "    # Zastosuj przyspieszenie do danych audio\n",
    "    stretched_wav = librosa.effects.time_stretch(wav_np, rate=speed_factor)\n",
    "    \n",
    "    return stretched_wav"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:53.004385300Z",
     "start_time": "2024-05-06T07:33:52.983413600Z"
    }
   },
   "id": "67cf914574ec5490",
   "execution_count": 93,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "speed_a = speed_up_audio(inc_a)\n",
    "speed_a"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:53.094246200Z",
     "start_time": "2024-05-06T07:33:53.000368300Z"
    }
   },
   "id": "476590ff59587d97",
   "execution_count": 94,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "plt.plot(speed_a)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:53.201754500Z",
     "start_time": "2024-05-06T07:33:53.048368800Z"
    }
   },
   "id": "80f0ea78896533bc",
   "execution_count": 95,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def slow_down_audio(wav, speed_factor=0.5):\n",
    "    # Konwertujemy tensor na tablicę numpy\n",
    "    wav_np = wav.numpy()\n",
    "    \n",
    "    # Przeprowadzamy zwolnienie tempa za pomocą librosa\n",
    "    slowed_wav_np = librosa.effects.time_stretch(wav_np, rate=speed_factor)\n",
    "    \n",
    "    # Konwertujemy wynikową tablicę numpy z powrotem na tensor TensorFlow\n",
    "    return tf.convert_to_tensor(slowed_wav_np, dtype=tf.float32)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:53.262101600Z",
     "start_time": "2024-05-06T07:33:53.203748600Z"
    }
   },
   "id": "375285678cc3b54b",
   "execution_count": 96,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "slow_a = slow_down_audio(wav)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:53.313979500Z",
     "start_time": "2024-05-06T07:33:53.219705600Z"
    }
   },
   "id": "d7e951cc87858dfa",
   "execution_count": 97,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "plt.plot(slow_a)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:53.547288300Z",
     "start_time": "2024-05-06T07:33:53.280075200Z"
    }
   },
   "id": "5d8e0e5b4d67e10d",
   "execution_count": 98,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:53.605134200Z",
     "start_time": "2024-05-06T07:33:53.545294200Z"
    }
   },
   "id": "3a04ac8276532875",
   "execution_count": 98,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "audio_processing_functions = [increase_amplitude, add_noise, time_masking, change_pitch]\n",
    "def process_random_samples(dataset, num_samples_to_process):\n",
    "    processed_samples = []\n",
    "    for _ in range(num_samples_to_process):\n",
    "        shuffled_dataset = dataset.shuffle(buffer_size=1000)\n",
    "        random_sample =  next(iter(shuffled_dataset.take(1)))\n",
    "\n",
    "        # Dobycie tensora z datasetu\n",
    "  # Tutaj uzyskujemy tensor danych audio\n",
    "\n",
    "        processing_function = random.choice(audio_processing_functions)\n",
    "        processed_sample = processing_function(random_sample)\n",
    "\n",
    "        processed_samples.append(processed_sample)\n",
    "\n",
    "    return processed_samples"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:53.609123200Z",
     "start_time": "2024-05-06T07:33:53.562248Z"
    }
   },
   "id": "ac294b85a18c5c3d",
   "execution_count": 99,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:53.627074700Z",
     "start_time": "2024-05-06T07:33:53.577208100Z"
    }
   },
   "id": "45987102e31ee2e2",
   "execution_count": 99,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Wczytaj, przetwórz i zapisz przetworzone pliki audio z pl_dataset_train\n",
    "pl_dataset_train_processed = pl_dataset_train.map(lambda filename: load_wav_16k_mono_and_resample(filename))\n",
    "pl_dataset_val_processed = pl_dataset_val.map(lambda filename:load_wav_16k_mono_and_resample(filename))\n",
    "pl_dataset_test_processed = pl_dataset_test.map(lambda filename: load_wav_16k_mono_and_resample(filename))\n",
    "# \n",
    "# pl_dataset_train_processed.as_numpy_iterator().next().shape[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:53.711789900Z",
     "start_time": "2024-05-06T07:33:53.596158300Z"
    }
   },
   "id": "22ccfc0099041c9e",
   "execution_count": 100,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "processed_samples_train = process_random_samples(pl_dataset_train_processed, TRAIN_SIZE - len(pl_dataset_train))\n",
    "processed_samples_val = process_random_samples(pl_dataset_val_processed, (VAL_SIZE - len(pl_dataset_val)))\n",
    "processed_samples_test = process_random_samples(pl_dataset_test_processed, (TEST_SIZE - len(pl_dataset_test)))\n",
    "# processed_samples_test"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:54.738736800Z",
     "start_time": "2024-05-06T07:33:53.701068800Z"
    }
   },
   "id": "3798bc6bccff9b18",
   "execution_count": 101,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-06T07:33:54.733751200Z"
    }
   },
   "id": "551560397a726105",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "align_processed_train = [align_probes(tensor, sample_rate) for tensor in processed_samples_train]\n",
    "align_processed_val = [align_probes(tensor, sample_rate) for tensor in processed_samples_val]\n",
    "align_processed_test = [align_probes(tensor, sample_rate) for tensor in processed_samples_test]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-06T07:33:54.735744800Z"
    }
   },
   "id": "297274267826dace",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "processed_samples_train_dataset = tf.data.Dataset.from_tensor_slices(align_processed_train)\n",
    "processed_samples_val_dataset = tf.data.Dataset.from_tensor_slices(align_processed_val)\n",
    "processed_samples_test_dataset = tf.data.Dataset.from_tensor_slices(align_processed_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T07:33:54.755715500Z",
     "start_time": "2024-05-06T07:33:54.738736800Z"
    }
   },
   "id": "a789f7eef861cb4f",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "processed_samples_test_dataset.as_numpy_iterator()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-06T07:33:54.741730500Z"
    }
   },
   "id": "78495d0f1138c0f",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "align_pl_dataset_train_with_processed_samples = pl_dataset_train_processed.map(lambda audio: align_probes(audio, sample_rate))\n",
    "align_pl_dataset_val_with_processed_samples = pl_dataset_val_processed.map(lambda audio: align_probes(audio, sample_rate))\n",
    "align_pl_dataset_test_with_processed_samples = pl_dataset_test_processed.map(lambda audio: align_probes(audio, sample_rate))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-06T07:33:54.743723300Z"
    }
   },
   "id": "abb91118a9271c66",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "align_pl_dataset_train_with_processed_samples_norm = align_pl_dataset_train_with_processed_samples.map(lambda audio: normalize_audio(audio))\n",
    "align_pl_dataset_val_with_processed_samples_norm = align_pl_dataset_val_with_processed_samples.map(lambda audio: normalize_audio(audio))\n",
    "align_pl_dataset_test_with_processed_samples_norm = align_pl_dataset_test_with_processed_samples.map(lambda audio: normalize_audio(audio))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-06T07:33:54.745718100Z"
    }
   },
   "id": "3da5eb659b8031a4",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def create_spectrogram(wav):\n",
    "    spectrogram = tf.signal.stft(wav, frame_length=320, frame_step=32)\n",
    "    spectrogram = tf.abs(spectrogram)\n",
    "    spectrogram = tf.expand_dims(spectrogram, axis=2)\n",
    "    return spectrogram"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-06T07:33:54.747712700Z"
    }
   },
   "id": "e2de33c855dae8d2",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "spectrogram = create_spectrogram(wav_example)\n",
    "\n",
    "\n",
    "spectrogram = tf.squeeze(spectrogram, axis=-1)\n",
    "# spectrogram_in_db = 20 * tf.math.log(spectrogram + 1e-10) / tf.math.log(10.0)\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.imshow(tf.transpose(spectrogram), aspect='auto', origin='lower', cmap='viridis', extent=[0, 10, 0, sample_rate / 2])\n",
    "plt.colorbar(label='Magnitude')\n",
    "plt.xlabel('Time [s]')\n",
    "plt.ylabel('Frequency [Hz]')\n",
    "plt.title('Spectrogram')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-06T07:33:54.748710600Z"
    }
   },
   "id": "92e3d39430f8ea23",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-06T07:33:54.749732600Z"
    }
   },
   "id": "9f24f866ac8858c",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "spectrogram = create_spectrogram(pitch_a)\n",
    "print(spectrogram.shape)\n",
    "\n",
    "spectrogram = tf.squeeze(spectrogram, axis=-1)\n",
    "print(spectrogram.shape)\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.imshow(tf.transpose(spectrogram), aspect='auto', origin='lower', cmap='viridis', extent=[0, 10, 0, sample_rate / 2])\n",
    "plt.colorbar(label='Magnitude')\n",
    "plt.xlabel('Time [s]')\n",
    "plt.ylabel('Frequency [Hz]')\n",
    "plt.title('Spectrogram')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-06T07:33:54.751702Z"
    }
   },
   "id": "82093256eee22ac0",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "spectrogram_pl_dataset_train = align_pl_dataset_train_with_processed_samples_norm.map(lambda audio: create_spectrogram(audio))\n",
    "spectrogram_pl_dataset_val = align_pl_dataset_val_with_processed_samples_norm.map(lambda audio: create_spectrogram(audio))\n",
    "spectrogram_pl_dataset_test = align_pl_dataset_test_with_processed_samples_norm.map(lambda audio: create_spectrogram(audio))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-06T07:33:54.752699400Z"
    }
   },
   "id": "994ed2ed4ea1fe63",
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
