{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Spoken language detection"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d758a0066910796d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7b90391470eb7da4"
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_io as tfio\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import IPython"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T15:42:15.980757Z",
     "start_time": "2024-05-17T15:42:13.933682Z"
    }
   },
   "id": "e771baad4b9578e9",
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "PL_DIR = os.path.join('languages_audio', 'languages_audio_wav', 'pl', 'clips')\n",
    "PL_DIR"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4343ebee9c38ae63",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# create tensorflow dataset\n",
    "pl_dataset = tf.data.Dataset.list_files(PL_DIR + '\\*.wav')\n",
    "pl_dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ba1dbf66c6eda4bf",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "pl_dataset.as_numpy_iterator().next()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9a641093a2c580c2",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "pl_dataset.as_numpy_iterator().next()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "88e49cfbfba3bafb",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df = pd.read_csv(os.path.join('languages_audio', 'languages_audio_mp3', 'pl', 'validated.tsv'), sep='\\t')\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b25c7c351f5d432",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df[df['gender'] == 'female_feminine']"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a419164919440f40",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df[df['gender'] == 'male_masculine']"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6c0ecc7926645f66",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df.groupby('sentence_id').count()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "805a0e99ad4a6f32",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df['sentence_id'].value_counts()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3765e7a31c9a897d",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df['sentence_id'].nunique()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "91c679c99c892a10",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df['client_id'].value_counts().sort_values(ascending=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fedb03302fc130ee",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "a8d7ac801357330b",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df[['sentence_id', 'client_id']].groupby(by='sentence_id').count().sort_values(by='client_id', ascending=False)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b66628d65d38615e",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df[['client_id', 'sentence_id']].sort_values(by='client_id', ascending=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "788ead3deb0c642a",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df[['client_id', 'sentence_id']].sort_values(by='client_id', ascending=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "54720b0b0d5e35f9",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df[df['client_id'] == 'ffffc00a5ed69f08a486837064ec2caeff21fe06264c3dd733f633fb6c2ae9aeb561a5a6f43e000554d4b3cc171644ba4ce971177af1cb54f9bd8cc153e71a5c']"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "28a7c157bc223a7",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# # sprawdzenie czy client_id oraz sequence_id się nie duplikują (czy jeden klient ma rózne sekwencej)\n",
    "# \n",
    "# for client_id in df['client_id'].unique():\n",
    "#     sentence_count = df['sentence_id'][df['client_id']  == client_id].count()\n",
    "#     client_id_count = df['client_id'][df['client_id']  == client_id].value_counts().iloc[0]\n",
    "#     if sentence_count != client_id_count:\n",
    "#         print(True)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "59ec3f2d2259223d",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df['sentence_id'][df['client_id']  == 'ffffc00a5ed69f08a486837064ec2caeff21fe06264c3dd733f633fb6c2ae9aeb561a5a6f43e000554d4b3cc171644ba4ce971177af1cb54f9bd8cc153e71a5c'].count()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "589f00618f423817",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df['client_id'][df['client_id']  == 'ffffc00a5ed69f08a486837064ec2caeff21fe06264c3dd733f633fb6c2ae9aeb561a5a6f43e000554d4b3cc171644ba4ce971177af1cb54f9bd8cc153e71a5c'].value_counts()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "833e078c9b16e7e2",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# TODO: WZiąć plik validated.tsv nastepnie podzielić go na mężczyzn i kobiety (dwa osobne dataset). następnie wrzucać do każdego ze zbiorów (najpiew testwoy, walidacyjny, treningowy) client_id od najmniejszej liczby wystąpień w obydwu  dopasować czas trwania każdej próbki (najpierw obcinać od środka, potem dopełniać zerami), zmienić na spektogram i dopiero wtedy dodać (koniec funkcji). druga funkcja będzie jako augumentowanie losowych danych (losowo wybiera funkcję która coś zrobi z danymi) jeżeli moje zbiory kobiet i mężczyzn nie będą spełniały wymaganej ilości próbek którą się poda. Na wyjściu ma być tensor z próbkami spektogramu. To zrobić finalnie dla każdego folderu (języka). Wtedy dopiero dodać label w formie one hot encoding"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b41eb727ab7bcbf8",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load data:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d07b8080fb6705c7"
  },
  {
   "cell_type": "code",
   "source": "df = pd.read_csv(os.path.join('..', '..', 'languages', 'pl', 'validated.tsv'), sep='\\t', usecols=['client_id', 'path', 'sentence_id', 'gender', 'locale'])",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T15:42:23.861502Z",
     "start_time": "2024-05-17T15:42:23.497144Z"
    }
   },
   "id": "1ba578e1c67f2d8d",
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Change mp3 to wav name"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8f69ec6d7189b945"
  },
  {
   "cell_type": "code",
   "source": [
    "# df = df.apply(lambda path: path.str.replace('.mp3', '.wav'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T15:42:23.864858Z",
     "start_time": "2024-05-17T15:42:23.862488Z"
    }
   },
   "id": "9422e72ec897347b",
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Split to woman and man sets"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e3481591ddd6b352"
  },
  {
   "cell_type": "code",
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T15:42:24.101468Z",
     "start_time": "2024-05-17T15:42:24.092060Z"
    }
   },
   "id": "437897c4a0dd254f",
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "woman_filter = df['gender'] == 'female_feminine'\n",
    "man_filter = df['gender'] == 'male_masculine'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T15:42:24.284161Z",
     "start_time": "2024-05-17T15:42:24.271164Z"
    }
   },
   "id": "5ea864f56b635651",
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df_women = df[woman_filter]\n",
    "df_women"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T15:42:24.465218Z",
     "start_time": "2024-05-17T15:42:24.457558Z"
    }
   },
   "id": "283bff5acfcbbefb",
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df_men = df[man_filter]\n",
    "df_men"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T15:42:24.753397Z",
     "start_time": "2024-05-17T15:42:24.743037Z"
    }
   },
   "id": "d227f88872caa27c",
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Set number of probes in my set and split it to train, validate and test"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bf90c16bcfef86e1"
  },
  {
   "cell_type": "code",
   "source": [
    "SET_SIZE = 3_000\n",
    "MAX_NUMBER_OF_CLIENT_ID = 3000\n",
    "MIN_CLIP_DURATION = 4000 #  clip time in [ms]\n",
    "\n",
    "TRAIN_SIZE = int(SET_SIZE * 0.6)\n",
    "VAL_SIZE = int((SET_SIZE - TRAIN_SIZE) // 2)\n",
    "TEST_SIZE = SET_SIZE - TRAIN_SIZE - VAL_SIZE\n",
    "\n",
    "print(f'Train size: {TRAIN_SIZE}')\n",
    "print(f'Validation size: {VAL_SIZE}')\n",
    "print(f'Test size: {TEST_SIZE}')\n",
    "print(f'Sum of sizes: {TRAIN_SIZE + VAL_SIZE + TEST_SIZE} is equal to SET_SIZE {TRAIN_SIZE + VAL_SIZE + TEST_SIZE == SET_SIZE}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T15:42:25.052214Z",
     "start_time": "2024-05-17T15:42:25.049102Z"
    }
   },
   "id": "73b6742e55cd46ce",
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Select probes with min that time \n",
    "df_clips_duration = pd.read_csv(os.path.join('..','..', 'languages', 'pl', 'clip_durations.tsv'), sep='\\t')\n",
    "df_clips_duration['clip'] = df_clips_duration['clip']\n",
    "df_men = df_men.merge(df_clips_duration, left_on='path', right_on='clip')\n",
    "df_men"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T15:42:25.541010Z",
     "start_time": "2024-05-17T15:42:25.403945Z"
    }
   },
   "id": "2bc35c9fa1f2a04a",
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "# \n",
    "# for i in range(len(df_clips_duration)):\n",
    "#     print(i)\n",
    "#     row_in_df = df_men[df_men['path']== df_clips_duration.iloc[i]['clip']] \n",
    "#     if (df_clips_duration.iloc[i]['duration[ms]'] >= MIN_CLIP_DURATION) and (len(row_in_df) >= 0):\n",
    "#         rows_over_min_dur_time = pd.concat([rows_over_min_dur_time, row_in_df])\n",
    "#     else:\n",
    "#         rows_under_min_dur_time = pd.concat([rows_under_min_dur_time, row_in_df])\n",
    "# \n",
    "# \n",
    "\n",
    "rows_over_min_dur_time = df_men[df_men['duration[ms]'] >= MIN_CLIP_DURATION]\n",
    "rows_under_min_dur_time = df_men[df_men['duration[ms]'] < MIN_CLIP_DURATION]\n",
    "rows_over_min_dur_time"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T15:42:25.555665Z",
     "start_time": "2024-05-17T15:42:25.542087Z"
    }
   },
   "id": "a901ecef326bfb2e",
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "rows_under_min_dur_time"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T15:42:25.629271Z",
     "start_time": "2024-05-17T15:42:25.621192Z"
    }
   },
   "id": "2fe7b8e7b0273d45",
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "if len(rows_over_min_dur_time) >= SET_SIZE:\n",
    "    df_men = rows_over_min_dur_time\n",
    "else:\n",
    "    df_men = pd.concat([rows_over_min_dur_time, rows_under_min_dur_time], ignore_index=True)[:SET_SIZE]\n",
    "\n",
    "df_men"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T15:42:25.838717Z",
     "start_time": "2024-05-17T15:42:25.831400Z"
    }
   },
   "id": "3a4ae1c66f24659e",
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df_train = pd.DataFrame()\n",
    "df_val = pd.DataFrame()\n",
    "df_test = pd.DataFrame()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T15:42:26.227348Z",
     "start_time": "2024-05-17T15:42:26.224015Z"
    }
   },
   "id": "94f0a7c187961064",
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df_counted_id = df_men['client_id'].value_counts(ascending=True)\n",
    "df_counted_id"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T15:42:26.501798Z",
     "start_time": "2024-05-17T15:42:26.494890Z"
    }
   },
   "id": "6219cdc9196dd3c8",
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "clients_form_origin_df = df_men[df_men['client_id'] == df_counted_id.index[200]]\n",
    "clients_form_origin_df1 = df_men[df_men['client_id'] == df_counted_id.index[201]]\n",
    "clients_form_origin_df1['client_id'].iloc[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T15:42:26.784605Z",
     "start_time": "2024-05-17T15:42:26.775857Z"
    }
   },
   "id": "b9d38e4396a58bfc",
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "for i in range(len(df_counted_id)):\n",
    "    print(df_counted_id.index[i], df_counted_id.iloc[i])\n",
    "    rows_form_origin_df = df_men[df_men['client_id'] == df_counted_id.index[i]][:MAX_NUMBER_OF_CLIENT_ID]\n",
    "    if len(rows_form_origin_df) <= (TEST_SIZE - len(df_test)) and rows_form_origin_df['client_id'].iloc[0]:\n",
    "        df_test = pd.concat([df_test, rows_form_origin_df], ignore_index=True)\n",
    "        continue\n",
    "    if len(df_test) < TEST_SIZE and rows_form_origin_df['client_id'].iloc[0]:\n",
    "        df_test = pd.concat([df_test, rows_form_origin_df[:(TEST_SIZE - len(df_test))]], ignore_index=True)\n",
    "        continue\n",
    "    if len(rows_form_origin_df) <= (VAL_SIZE - len(df_val)):\n",
    "        df_val = pd.concat([df_val, rows_form_origin_df], ignore_index=True)\n",
    "        continue\n",
    "    if len(df_val) < VAL_SIZE and rows_form_origin_df['client_id'].iloc[0]:\n",
    "        df_val = pd.concat([df_val, rows_form_origin_df[:(VAL_SIZE - len(df_val))]], ignore_index=True)\n",
    "        continue\n",
    "    if len(rows_form_origin_df) <= (TRAIN_SIZE - len(df_train)):\n",
    "        df_train = pd.concat([df_train, rows_form_origin_df], ignore_index=True)\n",
    "        continue\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T15:42:28.804668Z",
     "start_time": "2024-05-17T15:42:27.050860Z"
    }
   },
   "id": "537212501acba841",
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "df_test",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T15:42:28.812446Z",
     "start_time": "2024-05-17T15:42:28.805757Z"
    }
   },
   "id": "cfc9212855ee88ed",
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df_val"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T15:42:29.477652Z",
     "start_time": "2024-05-17T15:42:29.468310Z"
    }
   },
   "id": "34a10b1cb13de8b8",
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df_train"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T15:42:29.555092Z",
     "start_time": "2024-05-17T15:42:29.479278Z"
    }
   },
   "id": "b6d606986613d249",
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df_train['client_id'].value_counts(ascending=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T15:42:29.701935Z",
     "start_time": "2024-05-17T15:42:29.556098Z"
    }
   },
   "id": "2dc1f3507e88ca70",
   "execution_count": 20,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df_val['client_id'].value_counts(ascending=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T15:42:29.812369Z",
     "start_time": "2024-05-17T15:42:29.705996Z"
    }
   },
   "id": "b76854c74dcbe6ec",
   "execution_count": 21,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df_test['client_id'].value_counts(ascending=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T15:42:29.916395Z",
     "start_time": "2024-05-17T15:42:29.813233Z"
    }
   },
   "id": "b852eeccef319e18",
   "execution_count": 22,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Audio Preprocessing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "29260740840bf9d"
  },
  {
   "cell_type": "code",
   "source": [
    "df_test_filenames = df_test['path']\n",
    "df_val_filenames = df_val['path']\n",
    "df_train_filenames = df_train['path']\n",
    "df_test_filenames"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T15:42:29.978829Z",
     "start_time": "2024-05-17T15:42:29.917438Z"
    }
   },
   "id": "a8924444a65be459",
   "execution_count": 23,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T15:42:29.981687Z",
     "start_time": "2024-05-17T15:42:29.979753Z"
    }
   },
   "id": "ad8dc801a01d1723",
   "execution_count": 23,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df_val_filenames"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T15:42:30.121402Z",
     "start_time": "2024-05-17T15:42:29.982570Z"
    }
   },
   "id": "a365f15425586089",
   "execution_count": 24,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "PL_DIR = os.path.join('..','..', 'languages', 'pl', 'clips')\n",
    "PL_DIR"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T15:42:30.191080Z",
     "start_time": "2024-05-17T15:42:30.122221Z"
    }
   },
   "id": "6a0e645b674e76b8",
   "execution_count": 25,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# TEST\n",
    "df_train_filenames = df_train_filenames.apply(lambda fn: os.path.join(PL_DIR, fn))\n",
    "df_val_filenames = df_val_filenames.apply(lambda fn: os.path.join(PL_DIR, fn))\n",
    "df_test_filenames = df_test_filenames.apply(lambda fn: os.path.join(PL_DIR, fn))\n",
    "df_val_filenames"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T15:42:30.344647Z",
     "start_time": "2024-05-17T15:42:30.191850Z"
    }
   },
   "id": "48837fb6e1737922",
   "execution_count": 26,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# STARE\n",
    "# pl_dataset_train = tf.data.Dataset.from_tensor_slices(df_train_filenames.apply(lambda fn: os.path.join(PL_DIR, fn)))\n",
    "# pl_dataset_val = tf.data.Dataset.from_tensor_slices(df_val_filenames.apply(lambda fn: os.path.join(PL_DIR, fn)))\n",
    "# pl_dataset_test = tf.data.Dataset.from_tensor_slices(df_test_filenames.apply(lambda fn: os.path.join(PL_DIR, fn)))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T15:42:30.855386Z",
     "start_time": "2024-05-17T15:42:30.347132Z"
    }
   },
   "id": "8152a30b0143953a",
   "execution_count": 27,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "sample_rate = 48_000\n",
    "\n",
    "def add_zeros(wav, sample_rate):\n",
    "    time_probes = wav.shape[0]\n",
    "    missing_probes_one_side = int((MIN_CLIP_DURATION/1000* sample_rate - time_probes)//2)\n",
    "    padded_tensor = tf.pad(wav.numpy(), [[missing_probes_one_side, missing_probes_one_side]])\n",
    "    return tf.convert_to_tensor(padded_tensor, dtype=tf.float32)\n",
    "\n",
    "def cut_wav(wav, sample_rate):\n",
    "    time_probes = wav.shape[0]\n",
    "    # clip_dur_in_sec = time_probes / sample_rate\n",
    "    overlap = int((time_probes - (MIN_CLIP_DURATION/1000) * sample_rate)/2) \n",
    "    cut_clip = wav[overlap:(time_probes - overlap)]\n",
    "    return tf.convert_to_tensor(cut_clip, dtype=tf.float32)\n",
    "\n",
    "def load_wav_16k_mono_and_resample(filename, fin_sam_rate=16_000):\n",
    "    file_content = tf.io.read_file(filename)\n",
    "    wav = tfio.audio.decode_mp3(file_content)\n",
    "    wav = tf.squeeze(wav, axis=-1)\n",
    "    # sample_rate = tf.cast(sample_rate, dtype=tf.int32)\n",
    "    # wav = librosa.resample(wav.numpy(), orig_sr=sample_rate.numpy(), target_sr=fin_sam_rate)\n",
    "    # return wav\n",
    "    # return tf.convert_to_tensor(wav, dtype=tf.float32), sample_rate.numpy()\n",
    "    return tf.convert_to_tensor(wav, dtype=tf.float32)\n",
    "\n",
    "def load_and_align_probes(file_path):\n",
    "    wav = load_wav_16k_mono_and_resample(file_path)\n",
    "    expected_probes = int((MIN_CLIP_DURATION/1000) * sample_rate)\n",
    "    print(expected_probes)\n",
    "    current_probes = wav.shape[0]\n",
    "    print(current_probes)\n",
    "    if expected_probes > current_probes:\n",
    "        print(\"Add zeros\")\n",
    "        return add_zeros(wav, sample_rate)\n",
    "    elif expected_probes < current_probes:\n",
    "        print(\"Cut wav\")\n",
    "        return cut_wav(wav, sample_rate)\n",
    "    return tf.convert_to_tensor(wav, dtype=tf.float32)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T15:42:30.932987Z",
     "start_time": "2024-05-17T15:42:30.864245Z"
    }
   },
   "id": "9c8d53182f5b9bce",
   "execution_count": 28,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T15:42:30.935404Z",
     "start_time": "2024-05-17T15:42:30.933813Z"
    }
   },
   "id": "59b0b2f915f9abdd",
   "execution_count": 28,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T15:42:30.937842Z",
     "start_time": "2024-05-17T15:42:30.936322Z"
    }
   },
   "id": "3500453bde18d26e",
   "execution_count": 28,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_align_dataset = tf.data.Dataset.from_tensor_slices(df_train_filenames.apply(lambda filename: load_and_align_probes(filename)).to_list())\n",
    "test_align_dataset = tf.data.Dataset.from_tensor_slices(df_test_filenames.apply(lambda filename: load_and_align_probes(filename)).to_list())\n",
    "val_align_dataset = tf.data.Dataset.from_tensor_slices(df_val_filenames.apply(lambda filename: load_and_align_probes(filename)).to_list())\n",
    "\n",
    "test_align_dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T15:43:17.990215Z",
     "start_time": "2024-05-17T15:42:31.079911Z"
    }
   },
   "id": "72b7f3fb18b5c989",
   "execution_count": 29,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_align_dataset.as_numpy_iterator().next()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T15:43:18.647890Z",
     "start_time": "2024-05-17T15:43:17.991221Z"
    }
   },
   "id": "3b9b32aa07f7d3aa",
   "execution_count": 30,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def align_probes(wav, sample_rate):\n",
    "    # wav = load_wav_16k_mono_and_resample(file_path)\n",
    "    expected_probes = (MIN_CLIP_DURATION/1000) * sample_rate\n",
    "    print(expected_probes)\n",
    "    current_probes = wav.shape[0]\n",
    "    print(current_probes)\n",
    "    if expected_probes > current_probes:\n",
    "        print(\"Add zeros\")\n",
    "        return add_zeros(wav, sample_rate)\n",
    "    if expected_probes < current_probes:\n",
    "        print(\"Cut wav\")\n",
    "        return cut_wav(wav, sample_rate)\n",
    "    return wav\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T15:43:18.652187Z",
     "start_time": "2024-05-17T15:43:18.648691Z"
    }
   },
   "id": "f0a38271117d59b7",
   "execution_count": 31,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "MIN_CLIP_DURATION/1000* sample_rate"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T15:43:18.706296Z",
     "start_time": "2024-05-17T15:43:18.653981Z"
    }
   },
   "id": "94908a310416b0f0",
   "execution_count": 32,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def increase_amplitude(wav, min_increase=2.0, max_increase=5.0):\n",
    "    increased_wav = wav * random.uniform(min_increase, max_increase)\n",
    "    return tf.convert_to_tensor(increased_wav, dtype=tf.float32)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T15:43:18.753091Z",
     "start_time": "2024-05-17T15:43:18.707143Z"
    }
   },
   "id": "f6111e6d7401e4a5",
   "execution_count": 33,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def normalize_audio(wav):\n",
    "    max_amplitude = tf.reduce_max(tf.abs(wav))\n",
    "    normalized_wav = wav / max_amplitude  # Normalizacja do zakresu [-1, 1]\n",
    "    return normalized_wav"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T15:43:18.801880Z",
     "start_time": "2024-05-17T15:43:18.754075Z"
    }
   },
   "id": "bf9ffe4a7b8fc4f1",
   "execution_count": 34,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def add_noise(wav, noise_level=0.1):\n",
    "    noise = tf.random.normal(tf.shape(wav), mean=0.0, stddev=noise_level)\n",
    "    return wav + noise"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T15:43:18.849628Z",
     "start_time": "2024-05-17T15:43:18.802955Z"
    }
   },
   "id": "3d8db06681bdb844",
   "execution_count": 35,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def time_masking(wav, max_mask_length=10000):\n",
    "    # Sprawdzenie długości wav\n",
    "        # Sprawdzenie czy wav jest pusty lub ma nieprawidłowy kształt\n",
    "    if wav is None or tf.rank(wav) != 1:\n",
    "        return wav\n",
    "    \n",
    "    # Sprawdzenie długości wav\n",
    "    if tf.shape(wav)[0] <= max_mask_length:\n",
    "        return wav\n",
    "    \n",
    "    # Losowa długość maskowania\n",
    "    mask_length = tf.random.uniform([], maxval=max_mask_length, dtype=tf.int32)\n",
    "    \n",
    "    # Sprawdzenie, czy maska nie wyjdzie poza zakres\n",
    "    mask_start_max = tf.shape(wav)[0] - mask_length\n",
    "    mask_start = tf.random.uniform([], maxval=mask_start_max, dtype=tf.int32)\n",
    "    \n",
    "    # Stworzenie maski czasowej\n",
    "    mask = tf.concat([\n",
    "        tf.ones([mask_start]),\n",
    "        tf.zeros([mask_length]),\n",
    "        tf.ones([tf.shape(wav)[0] - mask_start - mask_length])\n",
    "    ], axis=0)\n",
    "    \n",
    "    # Zastosowanie maskowania do sygnału audio\n",
    "    masked_wav = wav * mask\n",
    "    \n",
    "    return masked_wav\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T15:43:18.898760Z",
     "start_time": "2024-05-17T15:43:18.850551Z"
    }
   },
   "id": "144e847d5de32db0",
   "execution_count": 36,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def change_pitch(wav, sample_rate=48000, pitch_shift=2):\n",
    "    wav_np = wav.numpy()  # Convert tensor to numpy array\n",
    "    pitched_wav = librosa.effects.pitch_shift(wav_np, sr=sample_rate, n_steps=pitch_shift)\n",
    "    return tf.convert_to_tensor(pitched_wav, dtype=tf.float32)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T15:43:18.958960Z",
     "start_time": "2024-05-17T15:43:18.899538Z"
    }
   },
   "id": "81222bca1cef8ca7",
   "execution_count": 37,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def speed_up_audio(wav, speed_factor=2):\n",
    "    wav_np = wav.numpy()\n",
    "    stretched_wav = librosa.effects.time_stretch(wav_np, rate=speed_factor)   \n",
    "    return stretched_wav"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T15:43:19.007606Z",
     "start_time": "2024-05-17T15:43:18.961038Z"
    }
   },
   "id": "67cf914574ec5490",
   "execution_count": 38,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def slow_down_audio(wav, speed_factor=0.5):\n",
    "    wav_np = wav.numpy()\n",
    "    slowed_wav_np = librosa.effects.time_stretch(wav_np, rate=speed_factor)\n",
    "    return tf.convert_to_tensor(slowed_wav_np, dtype=tf.float32)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T15:43:19.055415Z",
     "start_time": "2024-05-17T15:43:19.008537Z"
    }
   },
   "id": "375285678cc3b54b",
   "execution_count": 39,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "audio_processing_functions = [increase_amplitude, add_noise, time_masking]\n",
    "def process_random_samples(dataset, num_samples_to_process):\n",
    "    processed_samples = []\n",
    "    shuffled_dataset = dataset.shuffle(buffer_size=num_samples_to_process)\n",
    "    samples =  shuffled_dataset.take(num_samples_to_process)\n",
    "    for sample in samples:\n",
    "        processing_function = random.choice(audio_processing_functions)\n",
    "        processed_sample = processing_function(sample)\n",
    "    \n",
    "        processed_samples.append(processed_sample)\n",
    "\n",
    "    return processed_samples"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T15:43:19.104259Z",
     "start_time": "2024-05-17T15:43:19.056322Z"
    }
   },
   "id": "ac294b85a18c5c3d",
   "execution_count": 40,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "processed_samples_train = process_random_samples(train_align_dataset, TRAIN_SIZE - len(train_align_dataset))\n",
    "# processed_samples_val = process_random_samples(val_align_dataset, (VAL_SIZE - len(val_align_dataset)))\n",
    "# processed_samples_test = process_random_samples(test_align_dataset, (TEST_SIZE - len(test_align_dataset)))\n",
    "# processed_samples_test"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T15:43:19.844117Z",
     "start_time": "2024-05-17T15:43:19.105129Z"
    }
   },
   "id": "3798bc6bccff9b18",
   "execution_count": 41,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "align_processed_train = [align_probes(tensor, sample_rate) for tensor in processed_samples_train]\n",
    "# align_processed_val = [align_probes(tensor, sample_rate) for tensor in processed_samples_val]\n",
    "# align_processed_test = [align_probes(tensor,sample_rate) for tensor in processed_samples_test]\n",
    "align_processed_train"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T15:43:19.849932Z",
     "start_time": "2024-05-17T15:43:19.845078Z"
    }
   },
   "id": "297274267826dace",
   "execution_count": 42,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "processed_samples_train_dataset = tf.data.Dataset.from_tensor_slices(align_processed_train)\n",
    "# processed_samples_val_dataset = tf.data.Dataset.from_tensor_slices(align_processed_val)\n",
    "# processed_samples_test_dataset = tf.data.Dataset.from_tensor_slices(align_processed_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T15:43:19.905705Z",
     "start_time": "2024-05-17T15:43:19.851190Z"
    }
   },
   "id": "a789f7eef861cb4f",
   "execution_count": 43,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T15:43:27.260881Z",
     "start_time": "2024-05-17T15:43:27.259388Z"
    }
   },
   "id": "78495d0f1138c0f",
   "execution_count": 44,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "train_dataset_con = train_align_dataset.concatenate(processed_samples_train_dataset)\n",
    "# val_dataset_con = val_align_dataset.concatenate(processed_samples_val_dataset)\n",
    "# test_dataset_con = test_align_dataset.concatenate(processed_samples_test_dataset)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T15:43:29.733678Z",
     "start_time": "2024-05-17T15:43:29.730040Z"
    }
   },
   "id": "abb91118a9271c66",
   "execution_count": 45,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "align_pl_dataset_train_with_processed_samples_norm = train_dataset_con.map(lambda audio: normalize_audio(audio))\n",
    "align_pl_dataset_val_with_processed_samples_norm = val_align_dataset.map(lambda audio: normalize_audio(audio))\n",
    "align_pl_dataset_test_with_processed_samples_norm = test_align_dataset.map(lambda audio: normalize_audio(audio))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T15:43:30.355110Z",
     "start_time": "2024-05-17T15:43:30.293602Z"
    }
   },
   "id": "3da5eb659b8031a4",
   "execution_count": 46,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def create_spectrogram(wav):\n",
    "    spectrogram = tf.signal.stft(wav, frame_length=320, frame_step=32)\n",
    "    spectrogram = tf.abs(spectrogram)\n",
    "    spectrogram = tf.expand_dims(spectrogram, axis=2)\n",
    "    return spectrogram"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T15:43:30.591330Z",
     "start_time": "2024-05-17T15:43:30.588734Z"
    }
   },
   "id": "e2de33c855dae8d2",
   "execution_count": 47,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "spectrogram_pl_dataset_train = align_pl_dataset_train_with_processed_samples_norm.map(lambda audio: create_spectrogram(audio))\n",
    "spectrogram_pl_dataset_val = align_pl_dataset_val_with_processed_samples_norm.map(lambda audio: create_spectrogram(audio))\n",
    "spectrogram_pl_dataset_test = align_pl_dataset_test_with_processed_samples_norm.map(lambda audio: create_spectrogram(audio))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T15:43:31.018111Z",
     "start_time": "2024-05-17T15:43:30.863283Z"
    }
   },
   "id": "994ed2ed4ea1fe63",
   "execution_count": 48,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "spectrogram_pl_dataset_train"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T15:43:31.069713Z",
     "start_time": "2024-05-17T15:43:31.066520Z"
    }
   },
   "id": "91ece8457ac62112",
   "execution_count": 49,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "spectrogram_pl_dataset_val"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T15:43:31.281218Z",
     "start_time": "2024-05-17T15:43:31.278184Z"
    }
   },
   "id": "d1e27210b5266e61",
   "execution_count": 50,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "spectrogram_pl_dataset_test"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T15:43:31.497376Z",
     "start_time": "2024-05-17T15:43:31.494524Z"
    }
   },
   "id": "26b97f35b8ad06f9",
   "execution_count": 51,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "spectrogram_pl_dataset_test.as_numpy_iterator().next().shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T15:43:32.561Z",
     "start_time": "2024-05-17T15:43:32.280964Z"
    }
   },
   "id": "a896f7d090b76e59",
   "execution_count": 52,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T15:45:09.554840Z",
     "start_time": "2024-05-17T15:45:09.549659Z"
    }
   },
   "cell_type": "code",
   "source": [
    "languages = ['pl', 'en', 'ls']\n",
    "language_to_index = {lang: idx for idx, lang in enumerate(languages)}\n",
    "print(language_to_index)\n",
    "\n",
    "def one_hot_encode_language(lang):\n",
    "    lang_index = language_to_index[lang]\n",
    "    one_hot = tf.one_hot(lang_index, len(languages))\n",
    "    return one_hot\n",
    "\n",
    "one_hot_encode_language('en')"
   ],
   "id": "31b6cfa1b4efe396",
   "execution_count": 60,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "labeled_train_dataset = tf.data.Dataset.zip((spectrogram_pl_dataset_train, tf.data.Dataset.from_tensor_slices([one_hot_encode_language('en')] * len(spectrogram_pl_dataset_train))))\n",
    "labeled_val_dataset = tf.data.Dataset.zip((spectrogram_pl_dataset_val, tf.data.Dataset.from_tensor_slices(tf.ones(len(spectrogram_pl_dataset_val)))))\n",
    "labeled_test_dataset = tf.data.Dataset.zip((spectrogram_pl_dataset_test, tf.data.Dataset.from_tensor_slices(tf.ones(len(spectrogram_pl_dataset_test)))))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T15:46:44.617847Z",
     "start_time": "2024-05-17T15:46:44.592986Z"
    }
   },
   "id": "6d46c6b640e6deaa",
   "execution_count": 65,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "labeled_train_dataset.as_numpy_iterator().next()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T15:46:47.391773Z",
     "start_time": "2024-05-17T15:46:46.597862Z"
    }
   },
   "id": "5b930513b2d2ebfb",
   "execution_count": 66,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "labeled_val_dataset.as_numpy_iterator().next()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T15:43:34.827036Z",
     "start_time": "2024-05-17T15:43:34.520937Z"
    }
   },
   "id": "1fd73f0fbab8bea5",
   "execution_count": 55,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "labeled_test_dataset.as_numpy_iterator().next()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T15:43:36.229510Z",
     "start_time": "2024-05-17T15:43:35.878615Z"
    }
   },
   "id": "ddbc512a5fc9f74f",
   "execution_count": 56,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "568c51f7709b2f9b",
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
